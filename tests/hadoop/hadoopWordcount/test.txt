replaceOutput/cfhider/WordCount$IntSumReducer.class
replaceOutput/cfhider/WordCount$IntSumReducer$MyReducer.class
replaceOutput/cfhider/WordCount.class
replaceOutput/cfhider/WordCount$TokenizerMapper.class
replaceOutput/invoker/sgx_invoker.class
replaceOutput/ReplaceTestforHadoopWordCount.jar
Soot started on Sun May 24 09:38:20 CST 2020
Warning: org.codehaus.jackson.JsonGenerator is a phantom class!
Warning: org.codehaus.jackson.JsonFactory is a phantom class!
Warning: org.codehaus.jackson.map.ObjectMapper is a phantom class!
Warning: org.codehaus.jackson.map.JsonMappingException is a phantom class!
Warning: org.codehaus.jackson.JsonParseException is a phantom class!
Warning: org.apache.commons.io.FileUtils is a phantom class!
Warning: org.apache.commons.codec.binary.Base64 is a phantom class!
Warning: org.mortbay.util.ajax.JSON is a phantom class!
Warning: org.apache.commons.lang.StringUtils is a phantom class!
Warning: org.mortbay.jetty.webapp.WebAppContext is a phantom class!
Warning: javax.servlet.http.HttpServlet is a phantom class!
Warning: javax.servlet.http.HttpServletRequest is a phantom class!
Warning: javax.servlet.http.HttpServletResponse is a phantom class!
Warning: javax.servlet.ServletContext is a phantom class!
Warning: javax.servlet.ServletException is a phantom class!
Warning: org.mortbay.jetty.Connector is a phantom class!
Warning: org.mortbay.jetty.Handler is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandlerCollection is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler$SContext is a phantom class!
Warning: com.sun.jersey.spi.container.servlet.ServletContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.DefaultServlet is a phantom class!
Warning: org.mortbay.jetty.nio.SelectChannelConnector is a phantom class!
Warning: org.mortbay.thread.ThreadPool is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterMapping is a phantom class!
Warning: org.mortbay.util.MultiException is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHandler is a phantom class!
Warning: org.mortbay.thread.QueuedThreadPool is a phantom class!
Warning: org.mortbay.jetty.security.SslSocketConnector is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler is a phantom class!
Warning: org.mortbay.jetty.Server is a phantom class!
Warning: org.mortbay.jetty.HandlerContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterHolder is a phantom class!
Warning: org.mortbay.jetty.servlet.Context is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHolder is a phantom class!
Warning: org.apache.commons.httpclient.HttpMethod is a phantom class!
Warning: org.apache.commons.httpclient.HttpClient is a phantom class!
Warning: org.apache.commons.httpclient.methods.GetMethod is a phantom class!
Warning: org.apache.commons.httpclient.URI is a phantom class!
Warning: org.znerd.xmlenc.XMLOutputter is a phantom class!
Warning: org.apache.commons.configuration.PropertiesConfiguration is a phantom class!
Warning: org.apache.commons.math.util.MathUtils is a phantom class!
Warning: org.apache.commons.configuration.Configuration is a phantom class!
Warning: javax.servlet.ServletOutputStream is a phantom class!
Warning: javax.servlet.ServletConfig is a phantom class!
Warning: javax.servlet.ServletResponse is a phantom class!
Warning: javax.servlet.jsp.JspWriter is a phantom class!
Warning: javax.servlet.RequestDispatcher is a phantom class!
Warning: javax.servlet.ServletRequest is a phantom class!
Warning: javax.servlet.Filter is a phantom class!
Warning: javax.servlet.FilterChain is a phantom class!
Warning: javax.servlet.FilterConfig is a phantom class!
Warning: org.mortbay.jetty.security.ServletSSL is a phantom class!
Warning: org.mortbay.io.EndPoint is a phantom class!
Warning: org.mortbay.jetty.Request is a phantom class!
Warning: org.apache.log4j.Level is a phantom class!
Warning: org.apache.log4j.Logger is a phantom class!
Warning: org.apache.commons.lang.ArrayUtils is a phantom class!
Warning: org.apache.log4j.LogManager is a phantom class!
Warning: org.apache.log4j.Appender is a phantom class!
Warning: javax.ws.rs.GET is a phantom class!
Warning: javax.ws.rs.POST is a phantom class!
Warning: javax.ws.rs.core.Context is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilters is a phantom class!
Warning: javax.ws.rs.Produces is a phantom class!
Warning: javax.ws.rs.core.Response is a phantom class!
Warning: javax.ws.rs.Path is a phantom class!
Warning: javax.ws.rs.PUT is a phantom class!
Warning: javax.ws.rs.DefaultValue is a phantom class!
Warning: javax.ws.rs.PathParam is a phantom class!
Warning: javax.ws.rs.QueryParam is a phantom class!
Warning: javax.ws.rs.Consumes is a phantom class!
Warning: org.mortbay.log.Log is a phantom class!
Warning: org.apache.commons.daemon.Daemon is a phantom class!
Warning: org.apache.commons.daemon.DaemonContext is a phantom class!
Warning: javax.ws.rs.DELETE is a phantom class!
Warning: javax.ws.rs.core.StreamingOutput is a phantom class!
Warning: org.apache.commons.configuration.SubsetConfiguration is a phantom class!
Warning: org.apache.commons.configuration.ConfigurationException is a phantom class!
Warning: javax.servlet.http.HttpServletRequestWrapper is a phantom class!
Warning: org.apache.log4j.Priority is a phantom class!
Warning: org.apache.log4j.Category is a phantom class!
Warning: org.apache.log4j.FileAppender is a phantom class!
Warning: org.apache.log4j.helpers.QuietWriter is a phantom class!
Warning: org.apache.log4j.spi.LoggingEvent is a phantom class!
Warning: javax.ws.rs.core.Response$Status is a phantom class!
Warning: javax.ws.rs.core.Response$ResponseBuilder is a phantom class!
Warning: org.apache.log4j.AppenderSkeleton is a phantom class!
Warning: org.slf4j.Logger is a phantom class!
Warning: javax.servlet.http.Cookie is a phantom class!
Warning: org.slf4j.LoggerFactory is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilter is a phantom class!
Warning: javax.ws.rs.core.MultivaluedMap is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequestFilter is a phantom class!
Warning: javax.ws.rs.core.UriBuilder is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerResponseFilter is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequest is a phantom class!
No main class given. Inferred 'cfhider.WordCount' as main class.
[Call Graph] For information on where the call graph may be incomplete, use the verbose option to the cg phase.
[cf]SooClass:cfhider.WordCount$IntSumReducer
[cf] class: cfhider.WordCount$IntSumReducer
[cf] sootMethod:hasNOTActiveBody <init>
[controlflow list]:0 []
[cf] sootMethod:reduce
[controlflow]:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.IntWritable
[controlflow list]:2 [$z0, i0]
[cf] sootMethod-list:[$z0, i0]
[cf] sootMethod:reduce
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Iterable*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Iterable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Reducer$Context*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.mapreduce.Reducer$Context
[controlflow list]:0 []
[cf] sootMethod-list:[]
[CFMAP part]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}}
[cf]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[cf] class: cfhider.WordCount$IntSumReducer$MyReducer
[cf] sootMethod:hasNOTActiveBody <init>
[controlflow list]:0 []
[cf] sootMethod:reduce
[controlflow]:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.IntWritable
[controlflow list]:2 [$z0, i0]
[cf] sootMethod-list:[$z0, i0]
[cf] sootMethod:reduce
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Iterable*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Iterable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Reducer$Context*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.mapreduce.Reducer$Context
[controlflow list]:0 []
[cf] sootMethod-list:[]
[CFMAP part]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[$z0, i0]}}
[cf]SooClass:cfhider.WordCount
[cf] class: cfhider.WordCount
[cf] sootMethod:hasNOTActiveBody <init>
[controlflow list]:0 []
[cf] sootMethod:main
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String[]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Class
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[controlflow]:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
[controlflow list]:2 [$z0, $b0]
[cf] sootMethod-list:[$z0, $b0]
[CFMAP part]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[$z0, i0]}, cfhider.WordCount={main=[$z0, $b0]}}
[cf]SooClass:cfhider.WordCount$TokenizerMapper
[cf] class: cfhider.WordCount$TokenizerMapper
[cf] sootMethod:hasNOTActiveBody <init>
[controlflow list]:0 []
[cf] sootMethod:map
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
[controlflow]:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.String
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.IntWritable
[controlflow list]:1 [$z0]
[cf] sootMethod-list:[$z0]
[cf] sootMethod:map
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():java.lang.Object
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Mapper$Context*************
<<<<<<ZYSTBLE>>>>>>other Value.getType():org.apache.hadoop.mapreduce.Mapper$Context
[controlflow list]:0 []
[cf] sootMethod-list:[]
[cf] sootMethod:<clinit>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[controlflow list]:0 []
[cf] sootMethod-list:[]
[CFMAP part]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[$z0, i0]}, cfhider.WordCount={main=[$z0, $b0]}}
[cf]SooClass:invoker.sgx_invoker
[CFMAP]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[$z0, i0]}, cfhider.WordCount={main=[$z0, $b0]}}
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[taint] class: cfhider.WordCount$IntSumReducer$MyReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[taint] class: cfhider.WordCount$IntSumReducer$MyReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[taint] class: cfhider.WordCount$IntSumReducer$MyReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[taint] class: cfhider.WordCount$IntSumReducer$MyReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r6 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r6
isoutSetContains  false value:$r6 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r7
[taint source] u:(org.apache.hadoop.io.IntWritable) $r7
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r7
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$IntSumReducer$MyReducer
[taint] class: cfhider.WordCount$IntSumReducer$MyReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] Value:i0
flowThrough in :[i0]
flowThrough node:goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough in :[i0]
flowThrough node:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
[taint source] u:new org.apache.hadoop.io.IntWritable
flowThrough in :[i0]
flowThrough node:$r7 = new org.apache.hadoop.io.IntWritable
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  true value:i0 index:0
isSourceListContains  true value:i0 index:0
[taint source] u:$r7
flowThrough in :[i0]
flowThrough node:r8 = $r7
flowThrough out:[i0]
flowThrough in :[i0]
flowThrough node:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
flowThrough out:[i0]
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:r8
isoutSetContains  false value:r8 index:1
flowThrough in :[i0]
flowThrough node:return
flowThrough out:[i0]
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough in :[i0]
flowThrough node:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
flowThrough out:[i0]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
flowThrough in :[i0]
flowThrough node:r5 = (org.apache.hadoop.io.IntWritable) $r6
flowThrough out:[i0]
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough in :[i0]
flowThrough node:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
flowThrough out:[i0]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
flowThrough in :[i0]
flowThrough node:i0 = i0 + $i1
flowThrough out:[i0]
analysis.outSet.size():1
[TAINT]out:i0 type:int
[taint into] sootMethod: reduce
[$z0, i0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer$MyReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0, $b0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
[taint source] u:1
[taint source] u:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:$b0
isoutSetContains  false value:$b0 index:0
isSourceListContains  true value:$b0 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[========CFMAP=======after taint===]:{cfhider.WordCount$IntSumReducer={reduce=[$z0, i0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[$z0, i0]}, cfhider.WordCount={main=[$z0, $b0]}}
[==========memberVariables==after taint=========]:{}
[============staticmemberVariables=====after taint=======]:{}
Key class = cfhider.WordCount$IntSumReducer, Value = {reduce=[$z0, i0]}
Key1 method = reduce, Value1 = [$z0, i0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
tvalue:i0   type:int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount$TokenizerMapper, Value = {map=[$z0]}
Key1 method = map, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount$IntSumReducer$MyReducer, Value = {reduce=[$z0, i0]}
Key1 method = reduce, Value1 = [$z0, i0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
tvalue:i0   type:int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount, Value = {main=[$z0, $b0]}
Key1 method = main, Value1 = [$z0, $b0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
tvalue:$b0   type:byte
[========CFMAP==========]:{cfhider.WordCount$IntSumReducer={reduce=[i0, $z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount$IntSumReducer$MyReducer={reduce=[i0, $z0]}, cfhider.WordCount={main=[$z0, $b0]}}
[==========memberVariables===========]:{}
[============staticmemberVariables============]:{}
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer method = reduce, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$TokenizerMapper method = map, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer$MyReducer method = reduce, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Transforming cfhider.WordCount$IntSumReducer... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
tLocal=r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$IntSumReducer declaredFunction:<init>
**********************Line456
localArray:[r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
methodname :<init>
classname :org.apache.hadoop.mapreduce.Reducer
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=i0
tLocal=r4
tLocal=r5
tLocal=$r6
tLocal=$z0
tLocal=$r7
tLocal=$i1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: org.apache.hadoop.io.Text
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====i0 = 0
====currScanPre==0404=====r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
====currScanPre==0404=====$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
====currScanPre==0404=====if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
====currScanPre==0404=====r5 = (org.apache.hadoop.io.IntWritable) $r7
====currScanPre==0404=====$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
====currScanPre==0404=====i0 = i0 + $i1
====currScanPre==0404=====goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
====currScanPre==0404=====$r6 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, i0, r4, r5, $r6, $z0, $r7, $i1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals2
currProStmt is IdentityStmt:r1 := @parameter0: org.apache.hadoop.io.Text
0424 identity Vals r1 := @parameter0: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#i0 = 0#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#i0 = 0#----------------
currDefVals:[i0]
currDefVals after retainAll:[i0]
currUseVals:[0]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
i0: init stmt will be inserted into jimplefile! :i0 = 0
r4: init stmt will be inserted into jimplefile! :r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$i1: init stmt will be inserted into jimplefile! :$i1 = 0
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: i0 = 0
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: i0 = 0
ZYSTBLE condValsTypeArray:[2, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: i0 = 0;
toBeHiddenDefValues:[i0]
ass r curr pro Unit: 0;
ass r curr pro Unit type: int;
ass l curr pro Unit: i0;
ass l curr pro Unit type: int;
=curr pro Unit: 0;
Constant exp********0*************
values:********0*************
values.type:********int*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ i0 = 0++++++++++++++++++++++
=leftOpValue.type==int
=leftOpValue==i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=0
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :0 int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
add: else :0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
!setParam0
left_index:int_0
right_index:-1
return_index:100
counter:0
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r2, interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()]
currUseVals after retainAll:[]
assi methodname :iterator
assi classname :java.lang.Iterable
currProStmt isn't sensitive:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
line 701 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
currUseVals after retainAll:[]
assi methodname :hasNext
assi classname :java.util.Iterator
currProStmt isn't sensitive:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currProStmt will change to GET:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
new assi:$z0 = tmpResult1
ass r curr pro Unit: tmpResult1;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult1;
Local exp********tmpResult1*************
values:********tmpResult1*************
values.type:********boolean*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult1++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=1
return_index=101
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult1
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult1 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult1)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult1)  index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)  index:1
left_index:0
right_index:-1
return_index:101
counter:1
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto $r6 = new org.apache.hadoop.io.IntWritable;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====1
left_index is:====101
values1 is constant!
values.get(1):0
values.get(1).type:int
left_index====b==:101
right_index===b===:int_0
operator===b===:[ == ]
re===b===:-1
counter===b===:2
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $r6 = new org.apache.hadoop.io.IntWritable++++++++++++++++++++++
line 701 current stmt is: ----------#$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()]
currUseVals after retainAll:[]
assi methodname :next
assi classname :java.util.Iterator
currProStmt isn't sensitive:$r7 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
line 701 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r7#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r7#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r7, (org.apache.hadoop.io.IntWritable) $r7]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = (org.apache.hadoop.io.IntWritable) $r7;
line 701 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
currDefVals:[$i1]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()]
currUseVals after retainAll:[]
assi methodname :get
assi classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
line 701 current stmt is: ----------#i0 = i0 + $i1#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#i0 = i0 + $i1#----------------
currDefVals:[i0]
currDefVals after retainAll:[i0]
currUseVals:[i0, $i1, i0 + $i1]
currUseVals after retainAll:[i0]
currProStmt is AssignStmt: i0 = i0 + $i1;
toBeHiddenDefValues:[i0]
ass r curr pro Unit: i0 + $i1;
ass r curr pro Unit type: int;
ass l curr pro Unit: i0;
ass l curr pro Unit type: int;
=curr pro Unit: i0 + $i1;
Local exp********i0*************
Local exp********$i1*************
values:********i0*************
values.type:********int*************
values:********$i1*************
values.type:********int*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
operator:******** + *************
start insert before currStmt: ++++++++++++++++++++++++++ i0 = i0 + $i1++++++++++++++++++++++
=leftOpValue.type==int
=leftOpValue==i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=i0
pos_index=0
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=2
!!!!!enter!!!!!!!!!
values0 is cond val++++++++++++++i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
loggedValue type:int
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>($i1)++++++++++++++++++++++
-----------8.1------------
left_index:100
right_index:0
return_index:100
counter:3
line 701 current stmt is: ----------#goto [?= tmpResult1 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#goto [?= tmpResult1 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$r6 = new org.apache.hadoop.io.IntWritable#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r6 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.IntWritable]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r6 = new org.apache.hadoop.io.IntWritable;
line 701 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r6, i0, specialinvoke $r6.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)]
currUseVals after retainAll:[i0]
methodname :<init>
classname :org.apache.hadoop.io.IntWritable
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, r1, $r6, virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Reducer$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r6)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String)>(getUUID)#--
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r1
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r1, (org.apache.hadoop.io.Text) r1]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r1;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, $r4, r2, r3, virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)]
currUseVals after retainAll:[]
methodname :reduce
classname :cfhider.WordCount$IntSumReducer
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
Transforming cfhider.WordCount$IntSumReducer$MyReducer... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer$MyReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void <init>()>;
tLocal=r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer$MyReducer
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$IntSumReducer$MyReducer declaredFunction:<init>
**********************Line456
localArray:[r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer$MyReducer
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
methodname :<init>
classname :org.apache.hadoop.mapreduce.Reducer
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer$MyReducer
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void <init>()>;
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer$MyReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=i0
tLocal=r4
tLocal=r5
tLocal=$z0
tLocal=$r6
tLocal=$i1
tLocal=$r7
tLocal=r8
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer$MyReducer
====currScanPre==0404=====r1 := @parameter0: org.apache.hadoop.io.Text
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====i0 = 0
====currScanPre==0404=====r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
====currScanPre==0404=====$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
====currScanPre==0404=====if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
====currScanPre==0404=====r5 = (org.apache.hadoop.io.IntWritable) $r6
====currScanPre==0404=====$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
====currScanPre==0404=====i0 = i0 + $i1
====currScanPre==0404=====goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
====currScanPre==0404=====$r7 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)
====currScanPre==0404=====r8 = $r7
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, i0, r4, r5, $z0, $r6, $i1, $r7, r8, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals2
currProStmt is IdentityStmt:r1 := @parameter0: org.apache.hadoop.io.Text
0424 identity Vals r1 := @parameter0: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#i0 = 0#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#i0 = 0#----------------
currDefVals:[i0]
currDefVals after retainAll:[i0]
currUseVals:[0]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
i0: init stmt will be inserted into jimplefile! :i0 = 0
r4: init stmt will be inserted into jimplefile! :r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$i1: init stmt will be inserted into jimplefile! :$i1 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
r8: init stmt will be inserted into jimplefile! :r8 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: i0 = 0
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: i0 = 0
ZYSTBLE condValsTypeArray:[2, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: i0 = 0;
toBeHiddenDefValues:[i0]
ass r curr pro Unit: 0;
ass r curr pro Unit type: int;
ass l curr pro Unit: i0;
ass l curr pro Unit type: int;
=curr pro Unit: 0;
Constant exp********0*************
values:********0*************
values.type:********int*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ i0 = 0++++++++++++++++++++++
=leftOpValue.type==int
=leftOpValue==i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=0
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :0 int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
add: else :0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
!setParam0
left_index:int_0
right_index:-1
return_index:100
counter:4
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r2, interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()]
currUseVals after retainAll:[]
assi methodname :iterator
assi classname :java.lang.Iterable
currProStmt isn't sensitive:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
line 701 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
currUseVals after retainAll:[]
assi methodname :hasNext
assi classname :java.util.Iterator
currProStmt isn't sensitive:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currProStmt will change to GET:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
new assi:$z0 = tmpResult5
ass r curr pro Unit: tmpResult5;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult5;
Local exp********tmpResult5*************
values:********tmpResult5*************
values.type:********boolean*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult5++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=1
return_index=101
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult5
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult5 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult5
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult5)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult5)  index:0
left_index:0
right_index:-1
return_index:101
counter:5
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto $r7 = new org.apache.hadoop.io.IntWritable;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====1
left_index is:====101
values1 is constant!
values.get(1):0
values.get(1).type:int
left_index====b==:101
right_index===b===:int_0
operator===b===:[ == ]
re===b===:-1
counter===b===:6
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $r7 = new org.apache.hadoop.io.IntWritable++++++++++++++++++++++
line 701 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()]
currUseVals after retainAll:[]
assi methodname :next
assi classname :java.util.Iterator
currProStmt isn't sensitive:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
line 701 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r6, (org.apache.hadoop.io.IntWritable) $r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = (org.apache.hadoop.io.IntWritable) $r6;
line 701 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
currDefVals:[$i1]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()]
currUseVals after retainAll:[]
assi methodname :get
assi classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
line 701 current stmt is: ----------#i0 = i0 + $i1#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#i0 = i0 + $i1#----------------
currDefVals:[i0]
currDefVals after retainAll:[i0]
currUseVals:[i0, $i1, i0 + $i1]
currUseVals after retainAll:[i0]
currProStmt is AssignStmt: i0 = i0 + $i1;
toBeHiddenDefValues:[i0]
ass r curr pro Unit: i0 + $i1;
ass r curr pro Unit type: int;
ass l curr pro Unit: i0;
ass l curr pro Unit type: int;
=curr pro Unit: i0 + $i1;
Local exp********i0*************
Local exp********$i1*************
values:********i0*************
values.type:********int*************
values:********$i1*************
values.type:********int*************
rightCondValue1: []
condVals: [i0, $z0]
rightCondValue2: []
operator:******** + *************
start insert before currStmt: ++++++++++++++++++++++++++ i0 = i0 + $i1++++++++++++++++++++++
=leftOpValue.type==int
=leftOpValue==i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=i0
pos_index=0
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=2
!!!!!enter!!!!!!!!!
values0 is cond val++++++++++++++i0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
loggedValue type:int
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>($i1)++++++++++++++++++++++
-----------8.1------------
left_index:100
right_index:0
return_index:100
counter:7
line 701 current stmt is: ----------#goto [?= tmpResult5 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#goto [?= tmpResult5 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$r7 = new org.apache.hadoop.io.IntWritable#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r7 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.IntWritable]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = new org.apache.hadoop.io.IntWritable;
line 701 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, i0, specialinvoke $r7.<org.apache.hadoop.io.IntWritable: void <init>(int)>(i0)]
currUseVals after retainAll:[i0]
methodname :<init>
classname :org.apache.hadoop.io.IntWritable
line 701 current stmt is: ----------#r8 = $r7#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#r8 = $r7#----------------
currDefVals:[r8]
currDefVals after retainAll:[]
currUseVals:[$r7]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r8 = $r7;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, r1, r8, virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Reducer$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, r8)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String)>(getUUID)#--
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer$MyReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer$MyReducer
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r1
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r1, (org.apache.hadoop.io.Text) r1]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r1;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, $r4, r2, r3, virtualinvoke r0.<cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)]
currUseVals after retainAll:[]
methodname :reduce
classname :cfhider.WordCount$IntSumReducer$MyReducer
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$IntSumReducer$MyReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer$MyReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
Transforming cfhider.WordCount... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void <init>()>;
tLocal=r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount
====currScanPre==0404=====specialinvoke r0.<java.lang.Object: void <init>()>()
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount declaredFunction:<init>
**********************Line456
localArray:[r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
line 701 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount
 line632 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<java.lang.Object: void <init>()>()]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: specialinvoke r0.<java.lang.Object: void <init>()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: specialinvoke r0.<java.lang.Object: void <init>()>()
methodname :<init>
classname :java.lang.Object
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void <init>()>;
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void main(java.lang.String[])>;
tLocal=r0
tLocal=$r1
tLocal=r2
tLocal=r3
tLocal=r4
tLocal=r5
tLocal=$r6
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=$r11
tLocal=$r12
tLocal=$z0
tLocal=$b0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @parameter0: java.lang.String[]
====currScanPre==0404=====$r1 = <java.lang.System: java.io.PrintStream out>
====currScanPre==0404=====virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
====currScanPre==0404=====$r6 = new org.apache.hadoop.conf.Configuration
====currScanPre==0404=====specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
====currScanPre==0404=====r2 = $r6
====currScanPre==0404=====$r7 = new org.apache.hadoop.util.GenericOptionsParser
====currScanPre==0404=====specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
====currScanPre==0404=====r3 = $r7
====currScanPre==0404=====r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
====currScanPre==0404=====$r8 = new org.apache.hadoop.mapreduce.Job
====currScanPre==0404=====specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
====currScanPre==0404=====r5 = $r8
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
====currScanPre==0404=====$r9 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r10 = r4[0]
====currScanPre==0404=====specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
====currScanPre==0404=====$r11 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r12 = r4[1]
====currScanPre==0404=====specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
====currScanPre==0404=====$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
====currScanPre==0404=====if $z0 == 0 goto $b0 = 1
====currScanPre==0404=====$b0 = 0
====currScanPre==0404=====goto [?= staticinvoke <java.lang.System: void exit(int)>($b0)]
====currScanPre==0404=====$b0 = 1
====currScanPre==0404=====staticinvoke <java.lang.System: void exit(int)>($b0)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, $r1, r2, r3, r4, r5, $r6, $r7, $r8, $r9, $r10, $r11, $r12, $z0, $b0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals2
currProStmt is IdentityStmt:r0 := @parameter0: java.lang.String[]
0424 identity Vals r0 := @parameter0: java.lang.String[]
line 701 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[<java.lang.System: java.io.PrintStream out>]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
r2: init stmt will be inserted into jimplefile! :r2 = null
r3: init stmt will be inserted into jimplefile! :r3 = null
r4: init stmt will be inserted into jimplefile! :r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
$r11: init stmt will be inserted into jimplefile! :$r11 = null
$r12: init stmt will be inserted into jimplefile! :$r12 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$b0: init stmt will be inserted into jimplefile! :$b0 = 0
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
ZYSTBLE condValsTypeArray:[2, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: $r1 = <java.lang.System: java.io.PrintStream out>;
line 701 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, "In this project, we test wordcount with SGX!\n", virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")]
currUseVals after retainAll:[]
methodname :println
classname :java.io.PrintStream
currProStmt isn't sensitive invokestmt:virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.conf.Configuration]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r6 = new org.apache.hadoop.conf.Configuration;
line 701 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r6, specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.conf.Configuration
line 701 current stmt is: ----------#r2 = $r6#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#r2 = $r6#----------------
currDefVals:[r2]
currDefVals after retainAll:[]
currUseVals:[$r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r2 = $r6;
line 701 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.util.GenericOptionsParser]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = new org.apache.hadoop.util.GenericOptionsParser;
line 701 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, r2, r0, specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.util.GenericOptionsParser
line 701 current stmt is: ----------#r3 = $r7#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#r3 = $r7#----------------
currDefVals:[r3]
currDefVals after retainAll:[]
currUseVals:[$r7]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r3 = $r7;
line 701 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r3, virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()]
currUseVals after retainAll:[]
assi methodname :getRemainingArgs
assi classname :org.apache.hadoop.util.GenericOptionsParser
currProStmt isn't sensitive:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
line 701 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.mapreduce.Job]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r8 = new org.apache.hadoop.mapreduce.Job;
line 701 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r8, r2, "word count", specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Job
line 701 current stmt is: ----------#r5 = $r8#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#r5 = $r8#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r8]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r8;
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")]
currUseVals after retainAll:[]
methodname :setJarByClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$TokenizerMapper", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")]
currUseVals after retainAll:[]
methodname :setMapperClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setCombinerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setReducerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/Text", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")]
currUseVals after retainAll:[]
methodname :setOutputKeyClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/IntWritable", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")]
currUseVals after retainAll:[]
methodname :setOutputValueClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r9 = new org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r10 = r4[0]#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r10 = r4[0]#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[r4, 0, r4[0]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = r4[0];
line 701 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r9, $r10, specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r9, staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)]
currUseVals after retainAll:[]
methodname :addInputPath
classname :org.apache.hadoop.mapreduce.lib.input.FileInputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r11]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r11 = new org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r12 = r4[1]#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$r12 = r4[1]#----------------
currDefVals:[$r12]
currDefVals after retainAll:[]
currUseVals:[r4, 1, r4[1]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r12 = r4[1];
line 701 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r11, $r12, specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r11, staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)]
currUseVals after retainAll:[]
methodname :setOutputPath
classname :org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, 1, virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)]
currUseVals after retainAll:[]
assi methodname :waitForCompletion
assi classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currProStmt will change to GET:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
new assi:$z0 = tmpResult8
ass r curr pro Unit: tmpResult8;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult8;
Local exp********tmpResult8*************
values:********tmpResult8*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0, $b0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult8++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult8
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult8 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult8)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult8)  index:0
left_index:0
right_index:-1
return_index:100
counter:8
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#if $z0 == 0 goto $b0 = 1#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#if $z0 == 0 goto $b0 = 1#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto $b0 = 1;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
values1 is constant!
values.get(1):0
values.get(1).type:int
left_index====b==:100
right_index===b===:int_0
operator===b===:[ == ]
re===b===:-1
counter===b===:9
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $b0 = 1++++++++++++++++++++++
line 701 current stmt is: ----------#$b0 = 0#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$b0 = 0#----------------
currDefVals:[$b0]
currDefVals after retainAll:[$b0]
currUseVals:[0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b0 = 0;
toBeHiddenDefValues:[$b0]
ass r curr pro Unit: 0;
ass r curr pro Unit type: int;
ass l curr pro Unit: $b0;
ass l curr pro Unit type: byte;
=curr pro Unit: 0;
Constant exp********0*************
values:********0*************
values.type:********int*************
rightCondValue1: []
condVals: [$z0, $b0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $b0 = 0++++++++++++++++++++++
=leftOpValue.type==byte
=leftOpValue==$b0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
returnTypeIndex=1
pos_index=1
return_index=101
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=0
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :0 int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
add: else :0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
!setParam0
left_index:int_0
right_index:-1
return_index:101
counter:10
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#goto [?= staticinvoke <java.lang.System: void exit(int)>($b0)]#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#goto [?= staticinvoke <java.lang.System: void exit(int)>($b0)]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$b0 = 1#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#$b0 = 1#----------------
currDefVals:[$b0]
currDefVals after retainAll:[$b0]
currUseVals:[1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b0 = 1;
toBeHiddenDefValues:[$b0]
ass r curr pro Unit: 1;
ass r curr pro Unit type: int;
ass l curr pro Unit: $b0;
ass l curr pro Unit type: byte;
=curr pro Unit: 1;
Constant exp********1*************
values:********1*************
values.type:********int*************
rightCondValue1: []
condVals: [$z0, $b0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $b0 = 1++++++++++++++++++++++
=leftOpValue.type==byte
=leftOpValue==$b0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
returnTypeIndex=1
pos_index=1
return_index=101
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values.get(0)=1
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :1 int
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
add: else :1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
!setParam0
left_index:int_1
right_index:-1
return_index:101
counter:11
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>($b0)#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>($b0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$b0, staticinvoke <java.lang.System: void exit(int)>($b0)]
currUseVals after retainAll:[$b0]
methodname :exit
classname :java.lang.System
currProStmt isn't sensitive invokestmt:staticinvoke <java.lang.System: void exit(int)>($b0)
currProStmt isn't sensitive argList:1
new assi:tmpResult120 = $b0
<<<<<<ZYSTBLE>>>>>>replaceValueGetStmt AssignStmt leftOpValue is: ++++++++++++++++++++++++++tmpResult120++++++++++++++++++++++
Local exp********$b0*************
values length:1
<<<<<<ZYSTBLE>>>>>>the val is: $b0;
testValuesArrayList length is:1
newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void clear()>()++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ tmpResult120 = $b0++++++++++++++++++++++
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
<<<<<<ZYSTBLE>>>>>> tuple-0 Get: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size()==1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
val_type:1
pos_index:1
stmt get first operand:********101*************
stmt get second operand:********-1*************
curr stmttmpResult120 = $b0
leftOpValuetmpResult120
start insert an un-invoke get
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
zystble1:<invoker.sgx_invoker: int getIntValue(java.lang.String)>
general stmt--------------zystble3
0611============leftOpValue is: tmpResult120
0611============curr AssignStmt is: tmpResult120 = $b0
0611============newAssignStmt is: tmpResult120 = virtualinvoke sgxInvoker.<invoker.sgx_invoker: int getIntValue(java.lang.String)>(getUUID)
get counter:12
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void main(java.lang.String[])>;
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String)>(getUUID)#--
Transforming cfhider.WordCount$TokenizerMapper... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
tLocal=r0
tLocal=$r1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
====currScanPre==0404=====$r1 = new org.apache.hadoop.io.Text
====currScanPre==0404=====specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
====currScanPre==0404=====r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$TokenizerMapper declaredFunction:<init>
**********************Line456
localArray:[r0, $r1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
$r1: init stmt will be inserted into jimplefile! :$r1 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
methodname :<init>
classname :org.apache.hadoop.mapreduce.Mapper
line 701 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
 line632 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.Text]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r1 = new org.apache.hadoop.io.Text;
line 701 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
 line632 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.Text
line 701 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
 line632 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
currDefVals:[r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currDefVals after retainAll:[]
currUseVals:[r0, $r1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1;
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=r5
tLocal=$r6
tLocal=$z0
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: org.apache.hadoop.io.Text
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = new java.util.StringTokenizer
====currScanPre==0404=====$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
====currScanPre==0404=====specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
====currScanPre==0404=====r5 = $r4
====currScanPre==0404=====$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
====currScanPre==0404=====if $z0 == 0 goto return
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
====currScanPre==0404=====$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
====currScanPre==0404=====goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, $r4, r5, $r6, $z0, $r7, $r8, $r9, $r10, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: org.apache.hadoop.io.Text
0424 identity Vals r2 := @parameter1: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[new java.util.StringTokenizer]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = new java.util.StringTokenizer
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = new java.util.StringTokenizer
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: $r4 = new java.util.StringTokenizer;
line 701 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r2, virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
line 701 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r4, $r6, specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)]
currUseVals after retainAll:[]
methodname :<init>
classname :java.util.StringTokenizer
line 701 current stmt is: ----------#r5 = $r4#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#r5 = $r4#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r4;
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
currUseVals after retainAll:[]
assi methodname :hasMoreTokens
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currProStmt will change to GET:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
new assi:$z0 = tmpResult13
ass r curr pro Unit: tmpResult13;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult13;
Local exp********tmpResult13*************
values:********tmpResult13*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult13++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult13
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult13 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult13
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult13)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult13)  index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)  index:1
left_index:0
right_index:-1
return_index:100
counter:13
stmt update has no second operand:********-1*************
line 701 current stmt is: ----------#if $z0 == 0 goto return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#if $z0 == 0 goto return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto return;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
values1 is constant!
values.get(1):0
values.get(1).type:int
left_index====b==:100
right_index===b===:int_0
operator===b===:[ == ]
re===b===:-1
counter===b===:14
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto return++++++++++++++++++++++
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()]
currUseVals after retainAll:[]
assi methodname :nextToken
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, $r8, virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, $r9, $r10, virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Mapper$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#goto [?= tmpResult13 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#goto [?= tmpResult13 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String)>(getUUID)#--
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Object
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r2
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
====currScanPre==0404=====return
**********************Line456
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Object
0424 identity Vals r2 := @parameter1: java.lang.Object
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r2, (org.apache.hadoop.io.Text) r2]
currUseVals after retainAll:[]
r0: init stmt will be inserted into jimplefile! :r0 = null
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r2;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, r1, $r4, r3, virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)]
currUseVals after retainAll:[]
methodname :map
classname :cfhider.WordCount$TokenizerMapper
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void <clinit>()>;
tLocal=$r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====$r0 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
====currScanPre==0404=====<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
====currScanPre==0404=====return
**********************Line456
localArray:[$r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
line 701 current stmt is: ----------#$r0 = new org.apache.hadoop.io.IntWritable#----------------
***++++++lastIdentityStmt is:++++++++++$r0 = new org.apache.hadoop.io.IntWritable
 line632 current stmt is: ----------#$r0 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[$r0]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.IntWritable]
currUseVals after retainAll:[]
$r0: init stmt will be inserted into jimplefile! :$r0 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r0 = new org.apache.hadoop.io.IntWritable
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r0 = new org.apache.hadoop.io.IntWritable
currProStmt is AssignStmt: $r0 = new org.apache.hadoop.io.IntWritable;
line 701 current stmt is: ----------#specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)#----------------
***++++++lastIdentityStmt is:++++++++++$r0 = new org.apache.hadoop.io.IntWritable
 line632 current stmt is: ----------#specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r0, 1, specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.IntWritable
line 701 current stmt is: ----------#<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0#----------------
***++++++lastIdentityStmt is:++++++++++$r0 = new org.apache.hadoop.io.IntWritable
 line632 current stmt is: ----------#<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0#----------------
currDefVals:[<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>]
currDefVals after retainAll:[]
currUseVals:[$r0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0;
line 701 current stmt is: ----------#return#----------------
***++++++lastIdentityStmt is:++++++++++$r0 = new org.apache.hadoop.io.IntWritable
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void <clinit>()>;
Transforming invoker.sgx_invoker... 
Writing to replaceOutput/cfhider/WordCount$IntSumReducer.class
Writing to replaceOutput/cfhider/WordCount$IntSumReducer$MyReducer.class
Writing to replaceOutput/cfhider/WordCount.class
Writing to replaceOutput/cfhider/WordCount$TokenizerMapper.class
Writing to replaceOutput/invoker/sgx_invoker.class
Soot finished on Sun May 24 09:38:58 CST 2020
Soot has run for 0 min. 37 sec.
ok
