replaceOutput/cfhider/WordCount$IntSumReducer.class
replaceOutput/cfhider/WordCount.class
replaceOutput/cfhider/WordCount$TokenizerMapper.class
replaceOutput/invoker/sgx_invoker.class
replaceOutput/ReplaceTestforHadoopWordCount.jar
Soot started on Thu Nov 19 10:25:48 CST 2020
Warning: org.codehaus.jackson.JsonGenerator is a phantom class!
Warning: org.codehaus.jackson.JsonFactory is a phantom class!
Warning: org.codehaus.jackson.map.ObjectMapper is a phantom class!
Warning: org.codehaus.jackson.map.JsonMappingException is a phantom class!
Warning: org.codehaus.jackson.JsonParseException is a phantom class!
Warning: org.apache.commons.io.FileUtils is a phantom class!
Warning: org.apache.commons.codec.binary.Base64 is a phantom class!
Warning: org.mortbay.util.ajax.JSON is a phantom class!
Warning: org.apache.commons.lang.StringUtils is a phantom class!
Warning: org.mortbay.jetty.webapp.WebAppContext is a phantom class!
Warning: javax.servlet.http.HttpServlet is a phantom class!
Warning: javax.servlet.http.HttpServletRequest is a phantom class!
Warning: javax.servlet.http.HttpServletResponse is a phantom class!
Warning: javax.servlet.ServletContext is a phantom class!
Warning: javax.servlet.ServletException is a phantom class!
Warning: org.mortbay.jetty.Connector is a phantom class!
Warning: org.mortbay.jetty.Handler is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandlerCollection is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler$SContext is a phantom class!
Warning: com.sun.jersey.spi.container.servlet.ServletContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.DefaultServlet is a phantom class!
Warning: org.mortbay.jetty.nio.SelectChannelConnector is a phantom class!
Warning: org.mortbay.thread.ThreadPool is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterMapping is a phantom class!
Warning: org.mortbay.util.MultiException is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHandler is a phantom class!
Warning: org.mortbay.thread.QueuedThreadPool is a phantom class!
Warning: org.mortbay.jetty.security.SslSocketConnector is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler is a phantom class!
Warning: org.mortbay.jetty.Server is a phantom class!
Warning: org.mortbay.jetty.HandlerContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterHolder is a phantom class!
Warning: org.mortbay.jetty.servlet.Context is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHolder is a phantom class!
Warning: org.apache.commons.httpclient.HttpMethod is a phantom class!
Warning: org.apache.commons.httpclient.HttpClient is a phantom class!
Warning: org.apache.commons.httpclient.methods.GetMethod is a phantom class!
Warning: org.apache.commons.httpclient.URI is a phantom class!
Warning: org.znerd.xmlenc.XMLOutputter is a phantom class!
Warning: org.apache.commons.configuration.PropertiesConfiguration is a phantom class!
Warning: org.apache.commons.math.util.MathUtils is a phantom class!
Warning: org.apache.commons.configuration.Configuration is a phantom class!
Warning: javax.servlet.ServletOutputStream is a phantom class!
Warning: javax.servlet.ServletConfig is a phantom class!
Warning: javax.servlet.ServletResponse is a phantom class!
Warning: javax.servlet.jsp.JspWriter is a phantom class!
Warning: javax.servlet.RequestDispatcher is a phantom class!
Warning: javax.servlet.ServletRequest is a phantom class!
Warning: javax.servlet.Filter is a phantom class!
Warning: javax.servlet.FilterChain is a phantom class!
Warning: javax.servlet.FilterConfig is a phantom class!
Warning: org.mortbay.jetty.security.ServletSSL is a phantom class!
Warning: org.mortbay.io.EndPoint is a phantom class!
Warning: org.mortbay.jetty.Request is a phantom class!
Warning: org.apache.log4j.Level is a phantom class!
Warning: org.apache.log4j.Logger is a phantom class!
Warning: org.apache.commons.lang.ArrayUtils is a phantom class!
Warning: org.apache.log4j.LogManager is a phantom class!
Warning: org.apache.log4j.Appender is a phantom class!
Warning: javax.ws.rs.GET is a phantom class!
Warning: javax.ws.rs.POST is a phantom class!
Warning: javax.ws.rs.core.Context is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilters is a phantom class!
Warning: javax.ws.rs.Produces is a phantom class!
Warning: javax.ws.rs.core.Response is a phantom class!
Warning: javax.ws.rs.Path is a phantom class!
Warning: javax.ws.rs.PUT is a phantom class!
Warning: javax.ws.rs.DefaultValue is a phantom class!
Warning: javax.ws.rs.PathParam is a phantom class!
Warning: javax.ws.rs.QueryParam is a phantom class!
Warning: javax.ws.rs.Consumes is a phantom class!
Warning: org.mortbay.log.Log is a phantom class!
Warning: org.apache.commons.daemon.Daemon is a phantom class!
Warning: org.apache.commons.daemon.DaemonContext is a phantom class!
Warning: javax.ws.rs.DELETE is a phantom class!
Warning: javax.ws.rs.core.StreamingOutput is a phantom class!
Warning: org.apache.commons.configuration.SubsetConfiguration is a phantom class!
Warning: org.apache.commons.configuration.ConfigurationException is a phantom class!
Warning: javax.servlet.http.HttpServletRequestWrapper is a phantom class!
Warning: org.apache.log4j.Priority is a phantom class!
Warning: org.apache.log4j.Category is a phantom class!
Warning: org.apache.log4j.FileAppender is a phantom class!
Warning: org.apache.log4j.helpers.QuietWriter is a phantom class!
Warning: org.apache.log4j.spi.LoggingEvent is a phantom class!
Warning: javax.ws.rs.core.Response$Status is a phantom class!
Warning: javax.ws.rs.core.Response$ResponseBuilder is a phantom class!
Warning: org.apache.log4j.AppenderSkeleton is a phantom class!
Warning: org.slf4j.Logger is a phantom class!
Warning: javax.servlet.http.Cookie is a phantom class!
Warning: org.slf4j.LoggerFactory is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilter is a phantom class!
Warning: javax.ws.rs.core.MultivaluedMap is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequestFilter is a phantom class!
Warning: javax.ws.rs.core.UriBuilder is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerResponseFilter is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequest is a phantom class!
No main class given. Inferred 'cfhider.WordCount' as main class.
[Call Graph] For information on where the call graph may be incomplete, use the verbose option to the cg phase.
[cf]SooClass:cfhider.WordCount$IntSumReducer
[cf] class: cfhider.WordCount$IntSumReducer
[cf] sootMethod:hasNOTActiveBody <init>
[cf] sootMethod:reduce
[cf] sootMethod:reduce
[cf]SooClass:cfhider.WordCount
[cf] class: cfhider.WordCount
[cf] sootMethod:hasNOTActiveBody <init>
[cf] sootMethod:main
[cf]SooClass:cfhider.WordCount$TokenizerMapper
[cf] class: cfhider.WordCount$TokenizerMapper
[cf] sootMethod:hasNOTActiveBody <init>
[cf] sootMethod:map
[cf] sootMethod:map
[cf] sootMethod:<clinit>
[cf]SooClass:invoker.sgx_invoker
[CFMAP]:{cfhider.WordCount$IntSumReducer={reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@9c735e0}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@75a20a23}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@75a20a23}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6147bc2a}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@2c929b4b}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@2c929b4b}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@4d116fc9}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@3e7d61d7}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@19a28a4e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@19a28a4e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@19a28a4e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@7e261407}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@75ed1844}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@75ed1844}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@75ed1844}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@20d454d8}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@540e41be}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@540e41be}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@540e41be}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@73fe4c0e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33c21ca6}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@5296b140}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@234f0b1c}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@234f0b1c}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@1a626d60}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33fac728}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@33fac728}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@15292dc1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3c3366a0}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@12405d00}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3f99b45c}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3f99b45c}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3f99b45c}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@41024a3}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3fd54b6a}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3fd54b6a}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@3fd54b6a}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@4c4a3ce3}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@1de38236}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@1de38236}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@1de38236}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@4379b68e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@427ae4c1}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@1c852d0f}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6b514269}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6b514269}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@23df328a}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@126f146c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@126f146c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3aa5c7e8}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6bc0473d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6902a290}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2bfed1cc}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2bfed1cc}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2bfed1cc}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@667fbea4}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4cbd358e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4cbd358e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4cbd358e}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@1a0724fe}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4b0dad0b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4b0dad0b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@4b0dad0b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@6edbd3ab}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59e76e6c}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@5a6e0702}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6d8e42af}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6d8e42af}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@16bc275a}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@1abb915f}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@1abb915f}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=i0 rigth=i0 + $i1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$i1 rigth=virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=(org.apache.hadoop.io.IntWritable) $r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Object*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.Iterator*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:0
[taint source] u:r2
[taint source] u:interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
[taint source] u:r4
[taint source] u:interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
[taint source] u:$r6
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
[taint source] u:r5
[taint source] u:virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
[taint source] u:i0
[taint source] u:$i1
[taint source] u:i0 + $i1
analysis.outSet.size():0
[taint into] sootMethod: reduce
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@104501af}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[taint source] u:r1
[taint source] u:(org.apache.hadoop.io.Text) r1
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
[taint into] sootMethod: main
[$z0]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r18 rigth=virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r17 rigth=virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r16 rigth=virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r15 rigth=virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r14 rigth=new java.lang.StringBuilder
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.StringBuilder*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r13 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=d0 rigth=$d1 / 1000.0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$d1 rigth=(double) $l4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********double*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l4 rigth=$l3 - l0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$l3 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=b1 rigth=$b2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********byte*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r12 rigth=r4[1]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r11 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=r4[0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=new org.apache.hadoop.fs.Path
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.fs.Path*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r8
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=new org.apache.hadoop.mapreduce.Job
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.mapreduce.Job*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=l0 rigth=staticinvoke <java.lang.System: long currentTimeMillis()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********long*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r4 rigth=virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String[]*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r3 rigth=$r7
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=new org.apache.hadoop.util.GenericOptionsParser
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.util.GenericOptionsParser*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r2 rigth=$r6
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=new org.apache.hadoop.conf.Configuration
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.conf.Configuration*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r1 rigth=<java.lang.System: java.io.PrintStream out>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.io.PrintStream*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:new org.apache.hadoop.conf.Configuration
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
[taint source] u:$r6
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
[taint source] u:$r7
[taint source] u:r3
[taint source] u:virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:new org.apache.hadoop.mapreduce.Job
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r8
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:0
[taint source] u:r4[0]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
[taint source] u:new org.apache.hadoop.fs.Path
[taint source] u:r4
[taint source] u:1
[taint source] u:r4[1]
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
[taint source] u:r5
[taint source] u:1
[taint source] u:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:1
[taint source] u:0
[taint source] u:$b2
[taint source] u:staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
[taint source] u:$l3
[taint source] u:l0
[taint source] u:$l3 - l0
[taint source] u:$l4
[taint source] u:(double) $l4
[taint source] u:$d1
[taint source] u:1000.0
[taint source] u:$d1 / 1000.0
[taint source] u:<java.lang.System: java.io.PrintStream out>
[taint source] u:new java.lang.StringBuilder
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
[taint source] u:$r14
[taint source] u:"Job Finished in "
[taint source] u:virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r15
[taint source] u:d0
[taint source] u:virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
[taint source] u:$r16
[taint source] u:" seconds"
[taint source] u:virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
[taint source] u:$r17
[taint source] u:virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2225b869}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@4dc616d1}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@8041b3b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@8041b3b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@8041b3b}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@4597c299}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@6e68ee80}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@6e68ee80}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@6e68ee80}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@2b024e21}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@24576e96}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint into] sootMethod: <init>
[]
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@24576e96}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> rigth=$r1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r1 rigth=new org.apache.hadoop.io.Text
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
[taint source] u:new org.apache.hadoop.io.Text
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
[taint source] u:r0
[taint source] u:$r1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@24576e96}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r10 rigth=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r9 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r8 rigth=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r7 rigth=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$z0 rigth=virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
orignal data:$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=r5 rigth=$r4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r6 rigth=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=new java.util.StringTokenizer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.util.StringTokenizer*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:new java.util.StringTokenizer
[taint source] u:r2
[taint source] u:virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
[taint source] u:$r4
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r5
[taint source] u:virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
[taint source] u:r0
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
[taint into] sootMethod: map
[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@681d4c7d}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
left=$r4 rigth=(org.apache.hadoop.io.Text) r2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.Text*************
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[taint source] u:r2
[taint source] u:(org.apache.hadoop.io.Text) r2
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
[taint into] sootMethod: <clinit>
[]
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@22719081}, cfhider.WordCount$TokenizerMapper={map=[I@5b88d7f1}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> rigth=$r0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
left=$r0 rigth=new org.apache.hadoop.io.IntWritable
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********org.apache.hadoop.io.IntWritable*************
doAnalysis endqqqqqqq.....
come here
[taint source] u:new org.apache.hadoop.io.IntWritable
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
[taint source] u:$r0
analysis.outSet.size():0
[taint]SooClass:invoker.sgx_invoker
[========CFMAP=======after taint===]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}
[==========memberVariables==after taint=========]:{}
[============staticmemberVariables=====after taint=======]:{}
Key class = cfhider.WordCount$IntSumReducer, Value = {<init>=[], reduce=[$z0]}
Key1 method = <init>, Value1 = []
Key1 method = reduce, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount$TokenizerMapper, Value = {<init>=[], <clinit>=[], map=[$z0]}
Key1 method = <init>, Value1 = []
Key1 method = <clinit>, Value1 = []
Key1 method = map, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount, Value = {<init>=[], main=[$z0]}
Key1 method = <init>, Value1 = []
Key1 method = main, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
[add member]SooClass:cfhider.WordCount$IntSumReducer
[add member] class: cfhider.WordCount$IntSumReducer
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
[add member]SooClass:cfhider.WordCount
[add member] class: cfhider.WordCount
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
[add member]SooClass:cfhider.WordCount$TokenizerMapper
[add member] class: cfhider.WordCount$TokenizerMapper
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
[add member]SooClass:invoker.sgx_invoker
[========CFMAP==========]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[$z0]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[$z0]}}
[==========memberVariables===========]:{}
[============staticmemberVariables============]:{}
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer method = reduce, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$TokenizerMapper method = map, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Transforming cfhider.WordCount$IntSumReducer... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
tLocal=r0
tLocal=$r1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
====currScanPre==0404=====$r1 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
====currScanPre==0404=====r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$IntSumReducer declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, $r1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Reducer
currProStmt isn't sensitive invokestmt:specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r1 = new org.apache.hadoop.io.IntWritable#----------------
 line632 current stmt is: ----------#$r1 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.IntWritable]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r1 = new org.apache.hadoop.io.IntWritable;
currProStmt is NewExpr TypeString: org.apache.hadoop.io.IntWritable;
line 701 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive invokestmt:specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1#----------------
currDefVals:[r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currDefVals after retainAll:[]
currUseVals:[r0, $r1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1;
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=i0
tLocal=r4
tLocal=r5
tLocal=$z0
tLocal=$r6
tLocal=$i1
tLocal=$r7
tLocal=$r8
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: org.apache.hadoop.io.Text
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====i0 = 0
====currScanPre==0404=====r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
====currScanPre==0404=====$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
====currScanPre==0404=====if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
====currScanPre==0404=====r5 = (org.apache.hadoop.io.IntWritable) $r6
====currScanPre==0404=====$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
====currScanPre==0404=====i0 = i0 + $i1
====currScanPre==0404=====goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
====currScanPre==0404=====$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, r1, r2, r3, i0, r4, r5, $z0, $r6, $i1, $r7, $r8, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
currProStmt is IdentityStmt:r1 := @parameter0: org.apache.hadoop.io.Text
0424 identity Vals r1 := @parameter0: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#i0 = 0#----------------
 line632 current stmt is: ----------#i0 = 0#----------------
currDefVals:[i0]
currDefVals after retainAll:[]
currUseVals:[0]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
i0: init stmt will be inserted into jimplefile! :i0 = 0
r4: init stmt will be inserted into jimplefile! :r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$i1: init stmt will be inserted into jimplefile! :$i1 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: i0 = 0
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: i0 = 0
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: i0 = 0;
line 701 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
 line632 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r2, interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()]
currUseVals after retainAll:[]
assi methodname :iterator
assi classname :java.lang.Iterable
currProStmt isn't sensitive:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
line 701 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
 line632 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
currUseVals after retainAll:[]
assi methodname :hasNext
assi classname :java.util.Iterator
currProStmt isn't sensitive:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currProStmt will change to GET:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
new assi:$z0 = tmpResult0
ass r curr pro Unit: tmpResult0;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult0;
Local exp********tmpResult0*************
values:********tmpResult0*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult0++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult0
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult0 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult0)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult0)  index:0
left_index:0
right_index:-1
return_index:100
counter:0
stmt update has no second operand:********-1*************
1111222111
1111555111
line 701 current stmt is: ----------#if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:100
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:1
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>++++++++++++++++++++++
line 701 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
 line632 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()]
currUseVals after retainAll:[]
assi methodname :next
assi classname :java.util.Iterator
currProStmt isn't sensitive:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
line 701 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
 line632 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r6, (org.apache.hadoop.io.IntWritable) $r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = (org.apache.hadoop.io.IntWritable) $r6;
line 701 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
 line632 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
currDefVals:[$i1]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()]
currUseVals after retainAll:[]
assi methodname :get
assi classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
line 701 current stmt is: ----------#i0 = i0 + $i1#----------------
 line632 current stmt is: ----------#i0 = i0 + $i1#----------------
currDefVals:[i0]
currDefVals after retainAll:[]
currUseVals:[i0, $i1, i0 + $i1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: i0 = i0 + $i1;
line 701 current stmt is: ----------#goto [?= tmpResult0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
 line632 current stmt is: ----------#goto [?= tmpResult0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)#----------------
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, i0, virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)#----------------
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, r1, $r8, virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Reducer$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
A
C2
B
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, "", 0L)#--
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r1
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r1, (org.apache.hadoop.io.Text) r1]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r1;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, $r4, r2, r3, virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)]
currUseVals after retainAll:[]
methodname :reduce
classname :cfhider.WordCount$IntSumReducer
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
Transforming cfhider.WordCount... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void <init>()>;
tLocal=r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount
====currScanPre==0404=====specialinvoke r0.<java.lang.Object: void <init>()>()
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount;
localArray:[r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<java.lang.Object: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :java.lang.Object
currProStmt isn't sensitive invokestmt:specialinvoke r0.<java.lang.Object: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void main(java.lang.String[])>;
tLocal=r0
tLocal=$r1
tLocal=r2
tLocal=r3
tLocal=r4
tLocal=l0
tLocal=r5
tLocal=b1
tLocal=d0
tLocal=$r6
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=$r11
tLocal=$r12
tLocal=$z0
tLocal=$b2
tLocal=$l3
tLocal=$l4
tLocal=$d1
tLocal=$r13
tLocal=$r14
tLocal=$r15
tLocal=$r16
tLocal=$r17
tLocal=$r18
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @parameter0: java.lang.String[]
====currScanPre==0404=====$r1 = <java.lang.System: java.io.PrintStream out>
====currScanPre==0404=====virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
====currScanPre==0404=====$r6 = new org.apache.hadoop.conf.Configuration
====currScanPre==0404=====specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
====currScanPre==0404=====r2 = $r6
====currScanPre==0404=====$r7 = new org.apache.hadoop.util.GenericOptionsParser
====currScanPre==0404=====specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
====currScanPre==0404=====r3 = $r7
====currScanPre==0404=====r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
====currScanPre==0404=====l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
====currScanPre==0404=====$r8 = new org.apache.hadoop.mapreduce.Job
====currScanPre==0404=====specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
====currScanPre==0404=====r5 = $r8
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
====currScanPre==0404=====$r9 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r10 = r4[0]
====currScanPre==0404=====specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
====currScanPre==0404=====$r11 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r12 = r4[1]
====currScanPre==0404=====specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
====currScanPre==0404=====$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
====currScanPre==0404=====if $z0 == 0 goto $b2 = 1
====currScanPre==0404=====$b2 = 0
====currScanPre==0404=====goto [?= b1 = $b2]
====currScanPre==0404=====$b2 = 1
====currScanPre==0404=====b1 = $b2
====currScanPre==0404=====$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
====currScanPre==0404=====$l4 = $l3 - l0
====currScanPre==0404=====$d1 = (double) $l4
====currScanPre==0404=====d0 = $d1 / 1000.0
====currScanPre==0404=====$r13 = <java.lang.System: java.io.PrintStream out>
====currScanPre==0404=====$r14 = new java.lang.StringBuilder
====currScanPre==0404=====specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
====currScanPre==0404=====$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
====currScanPre==0404=====$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
====currScanPre==0404=====$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
====currScanPre==0404=====$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
====currScanPre==0404=====virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
====currScanPre==0404=====staticinvoke <java.lang.System: void exit(int)>(b1)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @parameter0: java.lang.String[];
localArray:[r0, $r1, r2, r3, r4, l0, r5, b1, d0, $r6, $r7, $r8, $r9, $r10, $r11, $r12, $z0, $b2, $l3, $l4, $d1, $r13, $r14, $r15, $r16, $r17, $r18, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r0 := @parameter0: java.lang.String[]
0424 identity Vals r0 := @parameter0: java.lang.String[]
line 701 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
 line632 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[<java.lang.System: java.io.PrintStream out>]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
r2: init stmt will be inserted into jimplefile! :r2 = null
r3: init stmt will be inserted into jimplefile! :r3 = null
r4: init stmt will be inserted into jimplefile! :r4 = null
l0: init stmt will be inserted into jimplefile! :l0 = 0L
r5: init stmt will be inserted into jimplefile! :r5 = null
b1: init stmt will be inserted into jimplefile! :b1 = 0
d0: init stmt will be inserted into jimplefile! :d0 = 0.0
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
$r11: init stmt will be inserted into jimplefile! :$r11 = null
$r12: init stmt will be inserted into jimplefile! :$r12 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$b2: init stmt will be inserted into jimplefile! :$b2 = 0
$l3: init stmt will be inserted into jimplefile! :$l3 = 0L
$l4: init stmt will be inserted into jimplefile! :$l4 = 0L
$d1: init stmt will be inserted into jimplefile! :$d1 = 0.0
$r13: init stmt will be inserted into jimplefile! :$r13 = null
$r14: init stmt will be inserted into jimplefile! :$r14 = null
$r15: init stmt will be inserted into jimplefile! :$r15 = null
$r16: init stmt will be inserted into jimplefile! :$r16 = null
$r17: init stmt will be inserted into jimplefile! :$r17 = null
$r18: init stmt will be inserted into jimplefile! :$r18 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is AssignStmt: $r1 = <java.lang.System: java.io.PrintStream out>;
line 701 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
 line632 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, "In this project, we test wordcount with SGX!\n", virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")]
currUseVals after retainAll:[]
methodname :println
classname :java.io.PrintStream
currProStmt isn't sensitive invokestmt:virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
 line632 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.conf.Configuration]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r6 = new org.apache.hadoop.conf.Configuration;
currProStmt is NewExpr TypeString: org.apache.hadoop.conf.Configuration;
line 701 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r6, specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.conf.Configuration
currProStmt isn't sensitive invokestmt:specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r2 = $r6#----------------
 line632 current stmt is: ----------#r2 = $r6#----------------
currDefVals:[r2]
currDefVals after retainAll:[]
currUseVals:[$r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r2 = $r6;
line 701 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
 line632 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.util.GenericOptionsParser]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r7 = new org.apache.hadoop.util.GenericOptionsParser;
currProStmt is NewExpr TypeString: org.apache.hadoop.util.GenericOptionsParser;
line 701 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
 line632 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, r2, r0, specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.util.GenericOptionsParser
currProStmt isn't sensitive invokestmt:specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#r3 = $r7#----------------
 line632 current stmt is: ----------#r3 = $r7#----------------
currDefVals:[r3]
currDefVals after retainAll:[]
currUseVals:[$r7]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r3 = $r7;
line 701 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
 line632 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r3, virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()]
currUseVals after retainAll:[]
assi methodname :getRemainingArgs
assi classname :org.apache.hadoop.util.GenericOptionsParser
currProStmt isn't sensitive:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
line 701 current stmt is: ----------#l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
 line632 current stmt is: ----------#l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
currDefVals:[l0]
currDefVals after retainAll:[]
currUseVals:[staticinvoke <java.lang.System: long currentTimeMillis()>()]
currUseVals after retainAll:[]
assi methodname :currentTimeMillis
assi classname :java.lang.System
currProStmt isn't sensitive:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
line 701 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
 line632 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.mapreduce.Job]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r8 = new org.apache.hadoop.mapreduce.Job;
currProStmt is NewExpr TypeString: org.apache.hadoop.mapreduce.Job;
line 701 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
 line632 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r8, r2, "word count", specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#r5 = $r8#----------------
 line632 current stmt is: ----------#r5 = $r8#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r8]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r8;
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")]
currUseVals after retainAll:[]
methodname :setJarByClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$TokenizerMapper", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")]
currUseVals after retainAll:[]
methodname :setMapperClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setCombinerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setReducerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/Text", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")]
currUseVals after retainAll:[]
methodname :setOutputKeyClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/IntWritable", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")]
currUseVals after retainAll:[]
methodname :setOutputValueClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
 line632 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r9 = new org.apache.hadoop.fs.Path;
currProStmt is NewExpr TypeString: org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r10 = r4[0]#----------------
 line632 current stmt is: ----------#$r10 = r4[0]#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[r4, 0, r4[0]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = r4[0];
line 701 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
 line632 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r9, $r10, specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
currProStmt isn't sensitive invokestmt:specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r9, staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)]
currUseVals after retainAll:[]
methodname :addInputPath
classname :org.apache.hadoop.mapreduce.lib.input.FileInputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
 line632 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r11]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r11 = new org.apache.hadoop.fs.Path;
currProStmt is NewExpr TypeString: org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r12 = r4[1]#----------------
 line632 current stmt is: ----------#$r12 = r4[1]#----------------
currDefVals:[$r12]
currDefVals after retainAll:[]
currUseVals:[r4, 1, r4[1]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r12 = r4[1];
line 701 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
 line632 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r11, $r12, specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
currProStmt isn't sensitive invokestmt:specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r11, staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)]
currUseVals after retainAll:[]
methodname :setOutputPath
classname :org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, 1, virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)]
currUseVals after retainAll:[]
assi methodname :waitForCompletion
assi classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currProStmt will change to GET:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
new assi:$z0 = tmpResult2
ass r curr pro Unit: tmpResult2;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult2;
Local exp********tmpResult2*************
values:********tmpResult2*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult2++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult2
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult2 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult2)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult2)  index:0
left_index:0
right_index:-1
return_index:100
counter:2
stmt update has no second operand:********-1*************
1111222111
1111555111
line 701 current stmt is: ----------#if $z0 == 0 goto $b2 = 1#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto $b2 = 1#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto $b2 = 1;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:100
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:3
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $b2 = 1++++++++++++++++++++++
line 701 current stmt is: ----------#$b2 = 0#----------------
 line632 current stmt is: ----------#$b2 = 0#----------------
currDefVals:[$b2]
currDefVals after retainAll:[]
currUseVals:[0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b2 = 0;
line 701 current stmt is: ----------#goto [?= b1 = $b2]#----------------
 line632 current stmt is: ----------#goto [?= b1 = $b2]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$b2 = 1#----------------
 line632 current stmt is: ----------#$b2 = 1#----------------
currDefVals:[$b2]
currDefVals after retainAll:[]
currUseVals:[1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b2 = 1;
line 701 current stmt is: ----------#b1 = $b2#----------------
 line632 current stmt is: ----------#b1 = $b2#----------------
currDefVals:[b1]
currDefVals after retainAll:[]
currUseVals:[$b2]
currUseVals after retainAll:[]
currProStmt is AssignStmt: b1 = $b2;
line 701 current stmt is: ----------#$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
 line632 current stmt is: ----------#$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
currDefVals:[$l3]
currDefVals after retainAll:[]
currUseVals:[staticinvoke <java.lang.System: long currentTimeMillis()>()]
currUseVals after retainAll:[]
assi methodname :currentTimeMillis
assi classname :java.lang.System
currProStmt isn't sensitive:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
line 701 current stmt is: ----------#$l4 = $l3 - l0#----------------
 line632 current stmt is: ----------#$l4 = $l3 - l0#----------------
currDefVals:[$l4]
currDefVals after retainAll:[]
currUseVals:[$l3, l0, $l3 - l0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $l4 = $l3 - l0;
line 701 current stmt is: ----------#$d1 = (double) $l4#----------------
 line632 current stmt is: ----------#$d1 = (double) $l4#----------------
currDefVals:[$d1]
currDefVals after retainAll:[]
currUseVals:[$l4, (double) $l4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $d1 = (double) $l4;
line 701 current stmt is: ----------#d0 = $d1 / 1000.0#----------------
 line632 current stmt is: ----------#d0 = $d1 / 1000.0#----------------
currDefVals:[d0]
currDefVals after retainAll:[]
currUseVals:[$d1, 1000.0, $d1 / 1000.0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: d0 = $d1 / 1000.0;
line 701 current stmt is: ----------#$r13 = <java.lang.System: java.io.PrintStream out>#----------------
 line632 current stmt is: ----------#$r13 = <java.lang.System: java.io.PrintStream out>#----------------
currDefVals:[$r13]
currDefVals after retainAll:[]
currUseVals:[<java.lang.System: java.io.PrintStream out>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r13 = <java.lang.System: java.io.PrintStream out>;
line 701 current stmt is: ----------#$r14 = new java.lang.StringBuilder#----------------
 line632 current stmt is: ----------#$r14 = new java.lang.StringBuilder#----------------
currDefVals:[$r14]
currDefVals after retainAll:[]
currUseVals:[new java.lang.StringBuilder]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r14 = new java.lang.StringBuilder;
currProStmt is NewExpr TypeString: java.lang.StringBuilder;
line 701 current stmt is: ----------#specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r14, specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :java.lang.StringBuilder
currProStmt isn't sensitive invokestmt:specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")#----------------
 line632 current stmt is: ----------#$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")#----------------
currDefVals:[$r15]
currDefVals after retainAll:[]
currUseVals:[$r14, "Job Finished in ", virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
line 701 current stmt is: ----------#$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)#----------------
 line632 current stmt is: ----------#$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)#----------------
currDefVals:[$r16]
currDefVals after retainAll:[]
currUseVals:[$r15, d0, virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
line 701 current stmt is: ----------#$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")#----------------
 line632 current stmt is: ----------#$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")#----------------
currDefVals:[$r17]
currDefVals after retainAll:[]
currUseVals:[$r16, " seconds", virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
line 701 current stmt is: ----------#$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()#----------------
 line632 current stmt is: ----------#$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()#----------------
currDefVals:[$r18]
currDefVals after retainAll:[]
currUseVals:[$r17, virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
line 701 current stmt is: ----------#virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)#----------------
 line632 current stmt is: ----------#virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r13, $r18, virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)]
currUseVals after retainAll:[]
methodname :println
classname :java.io.PrintStream
currProStmt isn't sensitive invokestmt:virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>(b1)#----------------
 line632 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>(b1)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[b1, staticinvoke <java.lang.System: void exit(int)>(b1)]
currUseVals after retainAll:[]
methodname :exit
classname :java.lang.System
currProStmt isn't sensitive invokestmt:staticinvoke <java.lang.System: void exit(int)>(b1)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void main(java.lang.String[])>;
A
C2
B
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, "", 0L)#--
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
Transforming cfhider.WordCount$TokenizerMapper... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
tLocal=r0
tLocal=$r1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
====currScanPre==0404=====$r1 = new org.apache.hadoop.io.Text
====currScanPre==0404=====specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
====currScanPre==0404=====r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$TokenizerMapper declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, $r1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Mapper
currProStmt isn't sensitive invokestmt:specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
 line632 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.Text]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r1 = new org.apache.hadoop.io.Text;
currProStmt is NewExpr TypeString: org.apache.hadoop.io.Text;
line 701 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
currDefVals:[r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currDefVals after retainAll:[]
currUseVals:[r0, $r1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1;
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=r5
tLocal=$r6
tLocal=$z0
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: org.apache.hadoop.io.Text
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = new java.util.StringTokenizer
====currScanPre==0404=====$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
====currScanPre==0404=====specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
====currScanPre==0404=====r5 = $r4
====currScanPre==0404=====$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
====currScanPre==0404=====if $z0 == 0 goto return
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
====currScanPre==0404=====$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
====currScanPre==0404=====goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, r5, $r6, $z0, $r7, $r8, $r9, $r10, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: org.apache.hadoop.io.Text
0424 identity Vals r2 := @parameter1: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
 line632 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[new java.util.StringTokenizer]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = new java.util.StringTokenizer
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = new java.util.StringTokenizer
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is NewExpr: $r4 = new java.util.StringTokenizer;
currProStmt is NewExpr TypeString: java.util.StringTokenizer;
line 701 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
 line632 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r2, virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
line 701 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
 line632 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r4, $r6, specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)]
currUseVals after retainAll:[]
methodname :<init>
classname :java.util.StringTokenizer
currProStmt isn't sensitive invokestmt:specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#r5 = $r4#----------------
 line632 current stmt is: ----------#r5 = $r4#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r4;
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
currUseVals after retainAll:[]
assi methodname :hasMoreTokens
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currProStmt will change to GET:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
new assi:$z0 = tmpResult4
ass r curr pro Unit: tmpResult4;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult4;
Local exp********tmpResult4*************
values:********tmpResult4*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult4++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult4
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult4 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult4
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult4)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult4)  index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(branchInvokeResult)  index:1
left_index:0
right_index:-1
return_index:100
counter:4
stmt update has no second operand:********-1*************
1111222111
1111555111
line 701 current stmt is: ----------#if $z0 == 0 goto return#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto return;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:100
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:5
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto return++++++++++++++++++++++
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
 line632 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()]
currUseVals after retainAll:[]
assi methodname :nextToken
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, $r8, virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
 line632 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, $r9, $r10, virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Mapper$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#goto [?= tmpResult4 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
 line632 current stmt is: ----------#goto [?= tmpResult4 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
A
C2
B
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, "", 0L)#--
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Object
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r2
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Object
0424 identity Vals r2 := @parameter1: java.lang.Object
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r2, (org.apache.hadoop.io.Text) r2]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r2;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, r1, $r4, r3, virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)]
currUseVals after retainAll:[]
methodname :map
classname :cfhider.WordCount$TokenizerMapper
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Transforming invoker.sgx_invoker... 
Writing to replaceOutput/cfhider/WordCount$IntSumReducer.class
Writing to replaceOutput/cfhider/WordCount.class
Writing to replaceOutput/cfhider/WordCount$TokenizerMapper.class
Writing to replaceOutput/invoker/sgx_invoker.class
Soot finished on Thu Nov 19 10:26:25 CST 2020
Soot has run for 0 min. 36 sec.
ok
