replaceOutput/cfhider/WordCount$IntSumReducer.class
replaceOutput/cfhider/WordCount.class
replaceOutput/cfhider/WordCount$TokenizerMapper.class
replaceOutput/invoker/sgx_invoker.class
replaceOutput/ReplaceTestforHadoopWordCount.jar
Soot started on Wed Apr 21 17:17:41 CST 2021
Warning: org.codehaus.jackson.JsonGenerator is a phantom class!
Warning: org.codehaus.jackson.JsonFactory is a phantom class!
Warning: org.codehaus.jackson.map.ObjectMapper is a phantom class!
Warning: org.codehaus.jackson.map.JsonMappingException is a phantom class!
Warning: org.codehaus.jackson.JsonParseException is a phantom class!
Warning: org.apache.commons.io.FileUtils is a phantom class!
Warning: org.apache.commons.codec.binary.Base64 is a phantom class!
Warning: org.mortbay.util.ajax.JSON is a phantom class!
Warning: org.apache.commons.lang.StringUtils is a phantom class!
Warning: org.mortbay.jetty.webapp.WebAppContext is a phantom class!
Warning: javax.servlet.http.HttpServlet is a phantom class!
Warning: javax.servlet.http.HttpServletRequest is a phantom class!
Warning: javax.servlet.http.HttpServletResponse is a phantom class!
Warning: javax.servlet.ServletContext is a phantom class!
Warning: javax.servlet.ServletException is a phantom class!
Warning: org.mortbay.jetty.Connector is a phantom class!
Warning: org.mortbay.jetty.Handler is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandlerCollection is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler$SContext is a phantom class!
Warning: com.sun.jersey.spi.container.servlet.ServletContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.DefaultServlet is a phantom class!
Warning: org.mortbay.jetty.nio.SelectChannelConnector is a phantom class!
Warning: org.mortbay.thread.ThreadPool is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterMapping is a phantom class!
Warning: org.mortbay.util.MultiException is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHandler is a phantom class!
Warning: org.mortbay.thread.QueuedThreadPool is a phantom class!
Warning: org.mortbay.jetty.security.SslSocketConnector is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler is a phantom class!
Warning: org.mortbay.jetty.Server is a phantom class!
Warning: org.mortbay.jetty.HandlerContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterHolder is a phantom class!
Warning: org.mortbay.jetty.servlet.Context is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHolder is a phantom class!
Warning: org.apache.commons.httpclient.HttpMethod is a phantom class!
Warning: org.apache.commons.httpclient.HttpClient is a phantom class!
Warning: org.apache.commons.httpclient.methods.GetMethod is a phantom class!
Warning: org.apache.commons.httpclient.URI is a phantom class!
Warning: org.znerd.xmlenc.XMLOutputter is a phantom class!
Warning: org.apache.commons.configuration.PropertiesConfiguration is a phantom class!
Warning: org.apache.commons.math.util.MathUtils is a phantom class!
Warning: org.apache.commons.configuration.Configuration is a phantom class!
Warning: javax.servlet.ServletOutputStream is a phantom class!
Warning: javax.servlet.ServletConfig is a phantom class!
Warning: javax.servlet.ServletResponse is a phantom class!
Warning: javax.servlet.jsp.JspWriter is a phantom class!
Warning: javax.servlet.RequestDispatcher is a phantom class!
Warning: javax.servlet.ServletRequest is a phantom class!
Warning: javax.servlet.Filter is a phantom class!
Warning: javax.servlet.FilterChain is a phantom class!
Warning: javax.servlet.FilterConfig is a phantom class!
Warning: org.mortbay.jetty.security.ServletSSL is a phantom class!
Warning: org.mortbay.io.EndPoint is a phantom class!
Warning: org.mortbay.jetty.Request is a phantom class!
Warning: org.apache.log4j.Level is a phantom class!
Warning: org.apache.log4j.Logger is a phantom class!
Warning: org.apache.commons.lang.ArrayUtils is a phantom class!
Warning: org.apache.log4j.LogManager is a phantom class!
Warning: org.apache.log4j.Appender is a phantom class!
Warning: javax.ws.rs.GET is a phantom class!
Warning: javax.ws.rs.POST is a phantom class!
Warning: javax.ws.rs.core.Context is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilters is a phantom class!
Warning: javax.ws.rs.Produces is a phantom class!
Warning: javax.ws.rs.core.Response is a phantom class!
Warning: javax.ws.rs.Path is a phantom class!
Warning: javax.ws.rs.PUT is a phantom class!
Warning: javax.ws.rs.DefaultValue is a phantom class!
Warning: javax.ws.rs.PathParam is a phantom class!
Warning: javax.ws.rs.QueryParam is a phantom class!
Warning: javax.ws.rs.Consumes is a phantom class!
Warning: org.mortbay.log.Log is a phantom class!
Warning: org.apache.commons.daemon.Daemon is a phantom class!
Warning: org.apache.commons.daemon.DaemonContext is a phantom class!
Warning: javax.ws.rs.DELETE is a phantom class!
Warning: javax.ws.rs.core.StreamingOutput is a phantom class!
Warning: org.apache.commons.configuration.SubsetConfiguration is a phantom class!
Warning: org.apache.commons.configuration.ConfigurationException is a phantom class!
Warning: javax.servlet.http.HttpServletRequestWrapper is a phantom class!
Warning: org.apache.log4j.Priority is a phantom class!
Warning: org.apache.log4j.Category is a phantom class!
Warning: org.apache.log4j.FileAppender is a phantom class!
Warning: org.apache.log4j.helpers.QuietWriter is a phantom class!
Warning: org.apache.log4j.spi.LoggingEvent is a phantom class!
Warning: javax.ws.rs.core.Response$Status is a phantom class!
Warning: javax.ws.rs.core.Response$ResponseBuilder is a phantom class!
Warning: org.apache.log4j.AppenderSkeleton is a phantom class!
Warning: org.slf4j.Logger is a phantom class!
Warning: javax.servlet.http.Cookie is a phantom class!
Warning: org.slf4j.LoggerFactory is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilter is a phantom class!
Warning: javax.ws.rs.core.MultivaluedMap is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequestFilter is a phantom class!
Warning: javax.ws.rs.core.UriBuilder is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerResponseFilter is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequest is a phantom class!
No main class given. Inferred 'cfhider.WordCount' as main class.
[Call Graph] For information on where the call graph may be incomplete, use the verbose option to the cg phase.
[cf]SooClass:cfhider.WordCount$IntSumReducer
[cf] class: cfhider.WordCount$IntSumReducer
[cf]SooClass:cfhider.WordCount
[cf] class: cfhider.WordCount
[cf]SooClass:cfhider.WordCount$TokenizerMapper
[cf] class: cfhider.WordCount$TokenizerMapper
2021class name :<init>
2021class name :map
[cf] sootMethod a:map
[cf] sootMethod zystble
unit :r0 := @this: cfhider.WordCount$TokenizerMapper
Identity statment
the value=r0
the value=@this: cfhider.WordCount$TokenizerMapper
unit :r1 := @parameter0: java.lang.Object
Identity statment
the value=r1
the value=@parameter0: java.lang.Object
unit :r2 := @parameter1: org.apache.hadoop.io.Text
Identity statment
the value=r2
the value=@parameter1: org.apache.hadoop.io.Text
unit :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Identity statment
the value=r3
the value=@parameter2: org.apache.hadoop.mapreduce.Mapper$Context
unit :$r4 = new java.util.StringTokenizer
AssignStmt statment
the value=$r4
2021=false taintSourceName=$z0
the value=new java.util.StringTokenizer
2021=false taintSourceName=$z0
unit :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
AssignStmt statment
the value=$r6
2021=false taintSourceName=$z0
the value=r2
2021=false taintSourceName=$z0
the value=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
2021=false taintSourceName=$z0
unit :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
unit :r5 = $r4
AssignStmt statment
the value=r5
2021=false taintSourceName=$z0
the value=$r4
2021=false taintSourceName=$z0
unit :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
AssignStmt statment
the value=$z0
2021=false taintSourceName=$z0
the value of newlist=[$z0]
unit :if $z0 == 0 goto return
If statment
the value=$z0
the value=0
unit :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
AssignStmt statment
the value=$r7
2021=false taintSourceName=$z0
the value=r0
2021=false taintSourceName=$z0
the value=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
2021=false taintSourceName=$z0
unit :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
AssignStmt statment
the value=$r8
2021=false taintSourceName=$z0
the value=r5
2021=false taintSourceName=$z0
the value=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
2021=false taintSourceName=$z0
unit :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
unit :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
AssignStmt statment
the value=$r9
2021=false taintSourceName=$z0
the value=r0
2021=false taintSourceName=$z0
the value=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
2021=false taintSourceName=$z0
unit :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
AssignStmt statment
the value=$r10
2021=false taintSourceName=$z0
the value=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
2021=false taintSourceName=$z0
unit :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
unit :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
unit :return
2021class name :map
[cf] sootMethod a:map
[cf] sootMethod zystble
unit :r0 := @this: cfhider.WordCount$TokenizerMapper
Identity statment
the value=r0
the value=@this: cfhider.WordCount$TokenizerMapper
unit :r1 := @parameter0: java.lang.Object
Identity statment
the value=r1
the value=@parameter0: java.lang.Object
unit :r2 := @parameter1: java.lang.Object
Identity statment
the value=r2
the value=@parameter1: java.lang.Object
unit :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Identity statment
the value=r3
the value=@parameter2: org.apache.hadoop.mapreduce.Mapper$Context
unit :$r4 = (org.apache.hadoop.io.Text) r2
AssignStmt statment
the value=$r4
2021=false taintSourceName=$z0
the value=r2
2021=false taintSourceName=$z0
the value=(org.apache.hadoop.io.Text) r2
2021=false taintSourceName=$z0
unit :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
unit :return
2021class name :<clinit>
[cf]SooClass:invoker.sgx_invoker
[CFMAP]2021:{cfhider.WordCount$IntSumReducer={}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@1b44f985}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@1b44f985, reduce=[I@4d5998bf}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@1b44f985, reduce=[I@353b4b45}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@47caba50
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@47caba50
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@47caba50
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4e8dff02, reduce=[I@353b4b45}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4e8dff02, reduce=[I@4c610498}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4e8dff02, reduce=[I@7574be54}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@437bb90a
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@437bb90a
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@437bb90a
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@7574be54}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@66a1df77}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@15fe56da
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@15fe56da
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@15fe56da
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={<init>=[I@3ad26bec}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={<init>=[I@3ad26bec, main=[I@2bfed1cc}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@2bfed1cc}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{map=[$z0]}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@5e7b3aa7}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@5e7b3aa7, map=[I@6c47da66}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@5e7b3aa7, map=[I@61539613}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@36a1eb50
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@36a1eb50
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@36a1eb50
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@5e7b3aa7, map=[I@61539613}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@405fed35, map=[I@61539613}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@405fed35, map=[I@59ce5397}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@405fed35, map=[I@78d20c90}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@2636ffe8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@2636ffe8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@2636ffe8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@405fed35, map=[I@78d20c90}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@64daebf1, map=[I@78d20c90}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@64daebf1, map=[I@60b84ef1}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@64daebf1, map=[I@6446e1d2}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6993d56c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6993d56c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6993d56c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@64daebf1, map=[I@6446e1d2}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@6446e1d2}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@18b19120}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@4e0a6581
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@4e0a6581
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@4e0a6581
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6fb16222, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@c8e202e, reduce=[I@d563245}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@c8e202e, reduce=[I@46e2b272}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@c8e202e, reduce=[I@4d317eb9}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@6c76cb46
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@6c76cb46
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6c76cb46
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6b1b984b, reduce=[I@4d317eb9}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6b1b984b, reduce=[I@60ab9adc}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@6b1b984b, reduce=[I@22441319}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@2341dfe2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@2341dfe2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@2341dfe2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@22441319}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@694c361c}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@667fbea4, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@6e430b06
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@6e430b06
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6e430b06
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@7388ef77, main=[I@4cbd358e}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@7388ef77, main=[I@2321a8e3}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@2321a8e3}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@68a0db9a, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@59d154a5, map=[I@31aed88a}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@59d154a5, map=[I@3e0c4ab4}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@59d154a5, map=[I@18fc8f3f}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6d207de9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6d207de9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6d207de9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@59d154a5, map=[I@18fc8f3f}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@702a83f7, map=[I@18fc8f3f}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@702a83f7, map=[I@773e06a8}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@702a83f7, map=[I@9273cc1}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@702a83f7, map=[I@9273cc1}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@5c3e2519, map=[I@9273cc1}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@5c3e2519, map=[I@73f5bb9e}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@5c3e2519, map=[I@9f0bd8c}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@1c2c376d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@1c2c376d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@1c2c376d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@5c3e2519, map=[I@9f0bd8c}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@9f0bd8c}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@33018d70}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@20d71633
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@20d71633
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@20d71633
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@39d18083, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@8f27f1d, reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@8f27f1d, reduce=[I@68774d81}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@8f27f1d, reduce=[I@708185bb}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4b59c01c, reduce=[I@708185bb}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4b59c01c, reduce=[I@715394e9}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@4b59c01c, reduce=[I@2655871f}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@391a17e2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@391a17e2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@391a17e2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@2655871f}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@496884a9}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@76d6e119, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@48611a39
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@48611a39
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@48611a39
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@5f00b94e, main=[I@15546d43}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@5f00b94e, main=[I@2885e09c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2885e09c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@1aeae38e, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@7a86c2d0, map=[I@2aecce39}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@7a86c2d0, map=[I@25602488}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@7a86c2d0, map=[I@4afe6fe3}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@663c68c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@663c68c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@663c68c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@7a86c2d0, map=[I@4afe6fe3}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@80149b, map=[I@4afe6fe3}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@80149b, map=[I@58c8cc5e}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@80149b, map=[I@66e15cdb}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@80149b, map=[I@66e15cdb}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@45cc63ed, map=[I@66e15cdb}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@45cc63ed, map=[I@6db48067}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@45cc63ed, map=[I@655a2275}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@8c634f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@8c634f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@8c634f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@45cc63ed, map=[I@655a2275}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@655a2275}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@46c5dabf}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@48cb6287
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@48cb6287
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@48cb6287
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@601613b7, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@20b1b267, reduce=[I@6cdd98e5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@20b1b267, reduce=[I@723798f5}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@20b1b267, reduce=[I@201b3768}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@5ad29d4f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@5ad29d4f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@5ad29d4f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@3955dc1e, reduce=[I@201b3768}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@3955dc1e, reduce=[I@33e652fa}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@3955dc1e, reduce=[I@5651b5b4}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@e7068b2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@e7068b2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@e7068b2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@5651b5b4}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@363d1b3d}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@6d5d368c, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@3d2e0f8
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@3d2e0f8
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@3d2e0f8
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@9afbbbe, main=[I@2a8596c}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@9afbbbe, main=[I@704ebbe9}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@4112f799, main=[I@704ebbe9}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
Have
the value=$z0
the value=0
maintainValues.size0
ifValues1
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@cbd7d1, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.Class*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********java.lang.String*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@216909a9, map=[I@679c55e5}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@216909a9, map=[I@76f94761}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@216909a9, map=[I@67bd6e4c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@459474c9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@459474c9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@459474c9
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@216909a9, map=[I@67bd6e4c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@157f5bcf, map=[I@67bd6e4c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@157f5bcf, map=[I@5c647e0f}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@157f5bcf, map=[I@49903a2c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@1bdb446f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@1bdb446f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@1bdb446f
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@157f5bcf, map=[I@49903a2c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@5869e1b2, map=[I@49903a2c}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@5869e1b2, map=[I@f609a77}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@5869e1b2, map=[I@f3d0284}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6e702fec
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6e702fec
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6e702fec
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@5869e1b2, map=[I@f3d0284}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@75a6799, map=[I@f3d0284}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
Have
the value=$z0
the value=0
maintainValues.size1
ifValues1
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@75a6799, map=[I@40477194}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@75a6799, map=[I@1271cc84}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6d29f791
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6d29f791
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6d29f791
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={<init>=[I@75e98585, reduce=[I@65c75d9c}, cfhider.WordCount$TokenizerMapper={<init>=[I@75a6799, map=[I@1271cc84}, cfhider.WordCount={<init>=[I@4112f799, main=[I@443d7f2f}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[========CFMAP=======after taint===]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}
[==========memberVariables==after taint=========]:{}
[============staticmemberVariables=====after taint=======]:{}
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer method = <init>, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer method = reduce, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$TokenizerMapper method = <init>, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$TokenizerMapper method = map, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount method = <init>, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount method = main, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Key class = cfhider.WordCount$IntSumReducer, Value = {<init>=[], reduce=[]}
Key1 method = <init>, Value1 = []
Key1 method = reduce, Value1 = []
Key class = cfhider.WordCount$TokenizerMapper, Value = {<init>=[], <clinit>=[], map=[$z0]}
Key1 method = <init>, Value1 = []
Key1 method = <clinit>, Value1 = []
Key1 method = map, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount, Value = {<init>=[], main=[]}
Key1 method = <init>, Value1 = []
Key1 method = main, Value1 = []
[add member]SooClass:cfhider.WordCount$IntSumReducer
[add member] class: cfhider.WordCount$IntSumReducer
[add member]SooClass:cfhider.WordCount
[add member] class: cfhider.WordCount
[add member]SooClass:cfhider.WordCount$TokenizerMapper
[add member] class: cfhider.WordCount$TokenizerMapper
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
[add member]SooClass:invoker.sgx_invoker
[========CFMAP==========]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}
[==========memberVariables===========]:{}
[============staticmemberVariables============]:{}
Transforming cfhider.WordCount$IntSumReducer... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
tLocal=r0
tLocal=$r1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
====currScanPre==0404=====$r1 = new org.apache.hadoop.io.IntWritable
====currScanPre==0404=====specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
====currScanPre==0404=====r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$IntSumReducer declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, $r1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$IntSumReducer: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Reducer
currProStmt isn't sensitive invokestmt:specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r1 = new org.apache.hadoop.io.IntWritable#----------------
 line632 current stmt is: ----------#$r1 = new org.apache.hadoop.io.IntWritable#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.IntWritable]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r1 = new org.apache.hadoop.io.IntWritable;
currProStmt is NewExpr TypeString: org.apache.hadoop.io.IntWritable;
line 701 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive invokestmt:specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1#----------------
currDefVals:[r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currDefVals after retainAll:[]
currUseVals:[r0, $r1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1;
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=i0
tLocal=r4
tLocal=r5
tLocal=$z0
tLocal=$r6
tLocal=$i1
tLocal=$r7
tLocal=$r8
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: org.apache.hadoop.io.Text
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====i0 = 0
====currScanPre==0404=====r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
====currScanPre==0404=====$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
====currScanPre==0404=====if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
====currScanPre==0404=====r5 = (org.apache.hadoop.io.IntWritable) $r6
====currScanPre==0404=====$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
====currScanPre==0404=====i0 = i0 + $i1
====currScanPre==0404=====goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
====currScanPre==0404=====$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, r1, r2, r3, i0, r4, r5, $z0, $r6, $i1, $r7, $r8, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
currProStmt is IdentityStmt:r1 := @parameter0: org.apache.hadoop.io.Text
0424 identity Vals r1 := @parameter0: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#i0 = 0#----------------
 line632 current stmt is: ----------#i0 = 0#----------------
currDefVals:[i0]
currDefVals after retainAll:[]
currUseVals:[0]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
i0: init stmt will be inserted into jimplefile! :i0 = 0
r4: init stmt will be inserted into jimplefile! :r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$i1: init stmt will be inserted into jimplefile! :$i1 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: i0 = 0
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: i0 = 0
currProStmt is AssignStmt: i0 = 0;
line 701 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
 line632 current stmt is: ----------#r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r2, interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()]
currUseVals after retainAll:[]
assi methodname :iterator
assi classname :java.lang.Iterable
currProStmt isn't sensitive:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
line 701 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
 line632 current stmt is: ----------#$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
currUseVals after retainAll:[]
assi methodname :hasNext
assi classname :java.util.Iterator
currProStmt isn't sensitive:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
line 701 current stmt is: ----------#if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[]
currProStmt is IfStmt: if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values0 is constant!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:boolean_$z0
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:0
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>++++++++++++++++++++++
line 701 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
 line632 current stmt is: ----------#$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r4, interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()]
currUseVals after retainAll:[]
assi methodname :next
assi classname :java.util.Iterator
currProStmt isn't sensitive:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
line 701 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
 line632 current stmt is: ----------#r5 = (org.apache.hadoop.io.IntWritable) $r6#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r6, (org.apache.hadoop.io.IntWritable) $r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = (org.apache.hadoop.io.IntWritable) $r6;
line 701 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
 line632 current stmt is: ----------#$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()#----------------
currDefVals:[$i1]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()]
currUseVals after retainAll:[]
assi methodname :get
assi classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
line 701 current stmt is: ----------#i0 = i0 + $i1#----------------
 line632 current stmt is: ----------#i0 = i0 + $i1#----------------
currDefVals:[i0]
currDefVals after retainAll:[]
currUseVals:[i0, $i1, i0 + $i1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: i0 = i0 + $i1;
line 701 current stmt is: ----------#goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
 line632 current stmt is: ----------#goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)#----------------
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, i0, virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.IntWritable
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
 line632 current stmt is: ----------#$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)#----------------
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, r1, $r8, virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Reducer$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$IntSumReducer
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$IntSumReducer
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Iterable
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r1
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$IntSumReducer;
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$IntSumReducer
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Iterable
0424 identity Vals r2 := @parameter1: java.lang.Iterable
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r1#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r1, (org.apache.hadoop.io.Text) r1]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r1
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r1;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, $r4, r2, r3, virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)]
currUseVals after retainAll:[]
methodname :reduce
classname :cfhider.WordCount$IntSumReducer
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
Transforming cfhider.WordCount... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void <init>()>;
tLocal=r0
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount
====currScanPre==0404=====specialinvoke r0.<java.lang.Object: void <init>()>()
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount;
localArray:[r0, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<java.lang.Object: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<java.lang.Object: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :java.lang.Object
currProStmt isn't sensitive invokestmt:specialinvoke r0.<java.lang.Object: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount: void main(java.lang.String[])>;
tLocal=r0
tLocal=$r1
tLocal=r2
tLocal=r3
tLocal=r4
tLocal=l0
tLocal=r5
tLocal=b1
tLocal=d0
tLocal=$r6
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=$r11
tLocal=$r12
tLocal=$z0
tLocal=$b2
tLocal=$l3
tLocal=$l4
tLocal=$d1
tLocal=$r13
tLocal=$r14
tLocal=$r15
tLocal=$r16
tLocal=$r17
tLocal=$r18
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @parameter0: java.lang.String[]
====currScanPre==0404=====$r1 = <java.lang.System: java.io.PrintStream out>
====currScanPre==0404=====virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
====currScanPre==0404=====$r6 = new org.apache.hadoop.conf.Configuration
====currScanPre==0404=====specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
====currScanPre==0404=====r2 = $r6
====currScanPre==0404=====$r7 = new org.apache.hadoop.util.GenericOptionsParser
====currScanPre==0404=====specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
====currScanPre==0404=====r3 = $r7
====currScanPre==0404=====r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
====currScanPre==0404=====l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
====currScanPre==0404=====$r8 = new org.apache.hadoop.mapreduce.Job
====currScanPre==0404=====specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
====currScanPre==0404=====r5 = $r8
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
====currScanPre==0404=====virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
====currScanPre==0404=====$r9 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r10 = r4[0]
====currScanPre==0404=====specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
====currScanPre==0404=====$r11 = new org.apache.hadoop.fs.Path
====currScanPre==0404=====$r12 = r4[1]
====currScanPre==0404=====specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
====currScanPre==0404=====staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
====currScanPre==0404=====$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
====currScanPre==0404=====if $z0 == 0 goto $b2 = 1
====currScanPre==0404=====$b2 = 0
====currScanPre==0404=====goto [?= b1 = $b2]
====currScanPre==0404=====$b2 = 1
====currScanPre==0404=====b1 = $b2
====currScanPre==0404=====$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
====currScanPre==0404=====$l4 = $l3 - l0
====currScanPre==0404=====$d1 = (double) $l4
====currScanPre==0404=====d0 = $d1 / 1000.0
====currScanPre==0404=====$r13 = <java.lang.System: java.io.PrintStream out>
====currScanPre==0404=====$r14 = new java.lang.StringBuilder
====currScanPre==0404=====specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
====currScanPre==0404=====$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
====currScanPre==0404=====$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
====currScanPre==0404=====$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
====currScanPre==0404=====$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
====currScanPre==0404=====virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
====currScanPre==0404=====staticinvoke <java.lang.System: void exit(int)>(b1)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @parameter0: java.lang.String[];
localArray:[r0, $r1, r2, r3, r4, l0, r5, b1, d0, $r6, $r7, $r8, $r9, $r10, $r11, $r12, $z0, $b2, $l3, $l4, $d1, $r13, $r14, $r15, $r16, $r17, $r18, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @parameter0: java.lang.String[]
0424 identity Vals r0 := @parameter0: java.lang.String[]
line 701 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
 line632 current stmt is: ----------#$r1 = <java.lang.System: java.io.PrintStream out>#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[<java.lang.System: java.io.PrintStream out>]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
r2: init stmt will be inserted into jimplefile! :r2 = null
r3: init stmt will be inserted into jimplefile! :r3 = null
r4: init stmt will be inserted into jimplefile! :r4 = null
l0: init stmt will be inserted into jimplefile! :l0 = 0L
r5: init stmt will be inserted into jimplefile! :r5 = null
b1: init stmt will be inserted into jimplefile! :b1 = 0
d0: init stmt will be inserted into jimplefile! :d0 = 0.0
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
$r11: init stmt will be inserted into jimplefile! :$r11 = null
$r12: init stmt will be inserted into jimplefile! :$r12 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$b2: init stmt will be inserted into jimplefile! :$b2 = 0
$l3: init stmt will be inserted into jimplefile! :$l3 = 0L
$l4: init stmt will be inserted into jimplefile! :$l4 = 0L
$d1: init stmt will be inserted into jimplefile! :$d1 = 0.0
$r13: init stmt will be inserted into jimplefile! :$r13 = null
$r14: init stmt will be inserted into jimplefile! :$r14 = null
$r15: init stmt will be inserted into jimplefile! :$r15 = null
$r16: init stmt will be inserted into jimplefile! :$r16 = null
$r17: init stmt will be inserted into jimplefile! :$r17 = null
$r18: init stmt will be inserted into jimplefile! :$r18 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r1 = <java.lang.System: java.io.PrintStream out>
currProStmt is AssignStmt: $r1 = <java.lang.System: java.io.PrintStream out>;
line 701 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
 line632 current stmt is: ----------#virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, "In this project, we test wordcount with SGX!\n", virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")]
currUseVals after retainAll:[]
methodname :println
classname :java.io.PrintStream
currProStmt isn't sensitive invokestmt:virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
 line632 current stmt is: ----------#$r6 = new org.apache.hadoop.conf.Configuration#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.conf.Configuration]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r6 = new org.apache.hadoop.conf.Configuration;
currProStmt is NewExpr TypeString: org.apache.hadoop.conf.Configuration;
line 701 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r6, specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.conf.Configuration
currProStmt isn't sensitive invokestmt:specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r2 = $r6#----------------
 line632 current stmt is: ----------#r2 = $r6#----------------
currDefVals:[r2]
currDefVals after retainAll:[]
currUseVals:[$r6]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r2 = $r6;
line 701 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
 line632 current stmt is: ----------#$r7 = new org.apache.hadoop.util.GenericOptionsParser#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.util.GenericOptionsParser]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r7 = new org.apache.hadoop.util.GenericOptionsParser;
currProStmt is NewExpr TypeString: org.apache.hadoop.util.GenericOptionsParser;
line 701 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
 line632 current stmt is: ----------#specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, r2, r0, specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.util.GenericOptionsParser
currProStmt isn't sensitive invokestmt:specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#r3 = $r7#----------------
 line632 current stmt is: ----------#r3 = $r7#----------------
currDefVals:[r3]
currDefVals after retainAll:[]
currUseVals:[$r7]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r3 = $r7;
line 701 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
 line632 current stmt is: ----------#r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()#----------------
currDefVals:[r4]
currDefVals after retainAll:[]
currUseVals:[r3, virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()]
currUseVals after retainAll:[]
assi methodname :getRemainingArgs
assi classname :org.apache.hadoop.util.GenericOptionsParser
currProStmt isn't sensitive:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
line 701 current stmt is: ----------#l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
 line632 current stmt is: ----------#l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
currDefVals:[l0]
currDefVals after retainAll:[]
currUseVals:[staticinvoke <java.lang.System: long currentTimeMillis()>()]
currUseVals after retainAll:[]
assi methodname :currentTimeMillis
assi classname :java.lang.System
currProStmt isn't sensitive:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
line 701 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
 line632 current stmt is: ----------#$r8 = new org.apache.hadoop.mapreduce.Job#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.mapreduce.Job]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r8 = new org.apache.hadoop.mapreduce.Job;
currProStmt is NewExpr TypeString: org.apache.hadoop.mapreduce.Job;
line 701 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
 line632 current stmt is: ----------#specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r8, r2, "word count", specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#r5 = $r8#----------------
 line632 current stmt is: ----------#r5 = $r8#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r8]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r8;
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")]
currUseVals after retainAll:[]
methodname :setJarByClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$TokenizerMapper", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")]
currUseVals after retainAll:[]
methodname :setMapperClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setCombinerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "cfhider/WordCount$IntSumReducer", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")]
currUseVals after retainAll:[]
methodname :setReducerClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/Text", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")]
currUseVals after retainAll:[]
methodname :setOutputKeyClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
 line632 current stmt is: ----------#virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, class "org/apache/hadoop/io/IntWritable", virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")]
currUseVals after retainAll:[]
methodname :setOutputValueClass
classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive invokestmt:virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
 line632 current stmt is: ----------#$r9 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r9 = new org.apache.hadoop.fs.Path;
currProStmt is NewExpr TypeString: org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r10 = r4[0]#----------------
 line632 current stmt is: ----------#$r10 = r4[0]#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[r4, 0, r4[0]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = r4[0];
line 701 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
 line632 current stmt is: ----------#specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r9, $r10, specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
currProStmt isn't sensitive invokestmt:specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r9, staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)]
currUseVals after retainAll:[]
methodname :addInputPath
classname :org.apache.hadoop.mapreduce.lib.input.FileInputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
 line632 current stmt is: ----------#$r11 = new org.apache.hadoop.fs.Path#----------------
currDefVals:[$r11]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.fs.Path]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r11 = new org.apache.hadoop.fs.Path;
currProStmt is NewExpr TypeString: org.apache.hadoop.fs.Path;
line 701 current stmt is: ----------#$r12 = r4[1]#----------------
 line632 current stmt is: ----------#$r12 = r4[1]#----------------
currDefVals:[$r12]
currDefVals after retainAll:[]
currUseVals:[r4, 1, r4[1]]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r12 = r4[1];
line 701 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
 line632 current stmt is: ----------#specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r11, $r12, specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.fs.Path
currProStmt isn't sensitive invokestmt:specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
 line632 current stmt is: ----------#staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r5, $r11, staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)]
currUseVals after retainAll:[]
methodname :setOutputPath
classname :org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
currProStmt isn't sensitive invokestmt:staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)#----------------
currDefVals:[$z0]
currDefVals after retainAll:[]
currUseVals:[r5, 1, virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)]
currUseVals after retainAll:[]
assi methodname :waitForCompletion
assi classname :org.apache.hadoop.mapreduce.Job
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
line 701 current stmt is: ----------#if $z0 == 0 goto $b2 = 1#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto $b2 = 1#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[]
currProStmt is IfStmt: if $z0 == 0 goto $b2 = 1;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values0 is constant!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:boolean_$z0
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:1
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto $b2 = 1++++++++++++++++++++++
line 701 current stmt is: ----------#$b2 = 0#----------------
 line632 current stmt is: ----------#$b2 = 0#----------------
currDefVals:[$b2]
currDefVals after retainAll:[]
currUseVals:[0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b2 = 0;
line 701 current stmt is: ----------#goto [?= b1 = $b2]#----------------
 line632 current stmt is: ----------#goto [?= b1 = $b2]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#$b2 = 1#----------------
 line632 current stmt is: ----------#$b2 = 1#----------------
currDefVals:[$b2]
currDefVals after retainAll:[]
currUseVals:[1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $b2 = 1;
line 701 current stmt is: ----------#b1 = $b2#----------------
 line632 current stmt is: ----------#b1 = $b2#----------------
currDefVals:[b1]
currDefVals after retainAll:[]
currUseVals:[$b2]
currUseVals after retainAll:[]
currProStmt is AssignStmt: b1 = $b2;
line 701 current stmt is: ----------#$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
 line632 current stmt is: ----------#$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()#----------------
currDefVals:[$l3]
currDefVals after retainAll:[]
currUseVals:[staticinvoke <java.lang.System: long currentTimeMillis()>()]
currUseVals after retainAll:[]
assi methodname :currentTimeMillis
assi classname :java.lang.System
currProStmt isn't sensitive:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
line 701 current stmt is: ----------#$l4 = $l3 - l0#----------------
 line632 current stmt is: ----------#$l4 = $l3 - l0#----------------
currDefVals:[$l4]
currDefVals after retainAll:[]
currUseVals:[$l3, l0, $l3 - l0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $l4 = $l3 - l0;
line 701 current stmt is: ----------#$d1 = (double) $l4#----------------
 line632 current stmt is: ----------#$d1 = (double) $l4#----------------
currDefVals:[$d1]
currDefVals after retainAll:[]
currUseVals:[$l4, (double) $l4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $d1 = (double) $l4;
line 701 current stmt is: ----------#d0 = $d1 / 1000.0#----------------
 line632 current stmt is: ----------#d0 = $d1 / 1000.0#----------------
currDefVals:[d0]
currDefVals after retainAll:[]
currUseVals:[$d1, 1000.0, $d1 / 1000.0]
currUseVals after retainAll:[]
currProStmt is AssignStmt: d0 = $d1 / 1000.0;
line 701 current stmt is: ----------#$r13 = <java.lang.System: java.io.PrintStream out>#----------------
 line632 current stmt is: ----------#$r13 = <java.lang.System: java.io.PrintStream out>#----------------
currDefVals:[$r13]
currDefVals after retainAll:[]
currUseVals:[<java.lang.System: java.io.PrintStream out>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r13 = <java.lang.System: java.io.PrintStream out>;
line 701 current stmt is: ----------#$r14 = new java.lang.StringBuilder#----------------
 line632 current stmt is: ----------#$r14 = new java.lang.StringBuilder#----------------
currDefVals:[$r14]
currDefVals after retainAll:[]
currUseVals:[new java.lang.StringBuilder]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r14 = new java.lang.StringBuilder;
currProStmt is NewExpr TypeString: java.lang.StringBuilder;
line 701 current stmt is: ----------#specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r14, specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :java.lang.StringBuilder
currProStmt isn't sensitive invokestmt:specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")#----------------
 line632 current stmt is: ----------#$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")#----------------
currDefVals:[$r15]
currDefVals after retainAll:[]
currUseVals:[$r14, "Job Finished in ", virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
line 701 current stmt is: ----------#$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)#----------------
 line632 current stmt is: ----------#$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)#----------------
currDefVals:[$r16]
currDefVals after retainAll:[]
currUseVals:[$r15, d0, virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
line 701 current stmt is: ----------#$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")#----------------
 line632 current stmt is: ----------#$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")#----------------
currDefVals:[$r17]
currDefVals after retainAll:[]
currUseVals:[$r16, " seconds", virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")]
currUseVals after retainAll:[]
assi methodname :append
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
line 701 current stmt is: ----------#$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()#----------------
 line632 current stmt is: ----------#$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()#----------------
currDefVals:[$r18]
currDefVals after retainAll:[]
currUseVals:[$r17, virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :java.lang.StringBuilder
currProStmt isn't sensitive:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
line 701 current stmt is: ----------#virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)#----------------
 line632 current stmt is: ----------#virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r13, $r18, virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)]
currUseVals after retainAll:[]
methodname :println
classname :java.io.PrintStream
currProStmt isn't sensitive invokestmt:virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>(b1)#----------------
 line632 current stmt is: ----------#staticinvoke <java.lang.System: void exit(int)>(b1)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[b1, staticinvoke <java.lang.System: void exit(int)>(b1)]
currUseVals after retainAll:[]
methodname :exit
classname :java.lang.System
currProStmt isn't sensitive invokestmt:staticinvoke <java.lang.System: void exit(int)>(b1)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount: void main(java.lang.String[])>;
***++++++lastIdentityStmt is:++++++++++r0 := @parameter0: java.lang.String[]
Transforming cfhider.WordCount$TokenizerMapper... 
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
tLocal=r0
tLocal=$r1
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
====currScanPre==0404=====$r1 = new org.apache.hadoop.io.Text
====currScanPre==0404=====specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
====currScanPre==0404=====r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
====currScanPre==0404=====return
Cuuid Classname:cfhider.WordCount$TokenizerMapper declaredFunction:<init>
zy3:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, $r1, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
line 701 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
 line632 current stmt is: ----------#uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()#----------------
currDefVals:[uuidtemp]
currDefVals after retainAll:[]
currUseVals:[sgxInvoker, virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
$r1: init stmt will be inserted into jimplefile! :$r1 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
assi methodname :getUUID
assi classname :invoker.sgx_invoker
currProStmt isn't sensitive:uuidtemp = virtualinvoke sgxInvoker.<invoker.sgx_invoker: java.lang.String getUUID()>()
line 701 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp#----------------
currDefVals:[r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid>]
currDefVals after retainAll:[]
currUseVals:[r0, uuidtemp]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$TokenizerMapper: java.lang.String Cuuid> = uuidtemp;
line 701 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.mapreduce.Mapper
currProStmt isn't sensitive invokestmt:specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
 line632 current stmt is: ----------#$r1 = new org.apache.hadoop.io.Text#----------------
currDefVals:[$r1]
currDefVals after retainAll:[]
currUseVals:[new org.apache.hadoop.io.Text]
currUseVals after retainAll:[]
currProStmt is NewExpr: $r1 = new org.apache.hadoop.io.Text;
currProStmt is NewExpr TypeString: org.apache.hadoop.io.Text;
line 701 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
 line632 current stmt is: ----------#specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r1, specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()]
currUseVals after retainAll:[]
methodname :<init>
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
currProStmt isn't sensitive argList:0
line 701 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
 line632 current stmt is: ----------#r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1#----------------
currDefVals:[r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currDefVals after retainAll:[]
currUseVals:[r0, $r1]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1;
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void <init>()>;
***++++++lastIdentityStmt is:++++++++++r0 := @this: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=r5
tLocal=$r6
tLocal=$z0
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: org.apache.hadoop.io.Text
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = new java.util.StringTokenizer
====currScanPre==0404=====$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
====currScanPre==0404=====specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
====currScanPre==0404=====r5 = $r4
====currScanPre==0404=====$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
====currScanPre==0404=====if $z0 == 0 goto return
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
====currScanPre==0404=====$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
====currScanPre==0404=====goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, r5, $r6, $z0, $r7, $r8, $r9, $r10, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: org.apache.hadoop.io.Text
0424 identity Vals r2 := @parameter1: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
 line632 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[new java.util.StringTokenizer]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = new java.util.StringTokenizer
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = new java.util.StringTokenizer
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is NewExpr: $r4 = new java.util.StringTokenizer;
currProStmt is NewExpr TypeString: java.util.StringTokenizer;
line 701 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
 line632 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r2, virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
line 701 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
 line632 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r4, $r6, specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)]
currUseVals after retainAll:[]
methodname :<init>
classname :java.util.StringTokenizer
currProStmt isn't sensitive invokestmt:specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#r5 = $r4#----------------
 line632 current stmt is: ----------#r5 = $r4#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r4;
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
currUseVals after retainAll:[]
assi methodname :hasMoreTokens
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currProStmt will change to GET:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
new assi:$z0 = tmpResult2
ass r curr pro Unit: tmpResult2;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult2;
Local exp********tmpResult2*************
values:********tmpResult2*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult2++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult2
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult2 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult2
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult2)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult2)  index:0
left_index:0
right_index:-1
return_index:100
counter:2
stmt update has no second operand:********-1*************
1111222111
1111555111
line 701 current stmt is: ----------#if $z0 == 0 goto return#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
currProStmt is IfStmt: if $z0 == 0 goto return;
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:100
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:3
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto return++++++++++++++++++++++
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
 line632 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()]
currUseVals after retainAll:[]
assi methodname :nextToken
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, $r8, virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
 line632 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, $r9, $r10, virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Mapper$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#goto [?= tmpResult2 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
 line632 current stmt is: ----------#goto [?= tmpResult2 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
A
C2
B
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, "", 0L)#--
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Object
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r2
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Object
0424 identity Vals r2 := @parameter1: java.lang.Object
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r2, (org.apache.hadoop.io.Text) r2]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r2;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, r1, $r4, r3, virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)]
currUseVals after retainAll:[]
methodname :map
classname :cfhider.WordCount$TokenizerMapper
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Transforming invoker.sgx_invoker... 
Writing to replaceOutput/cfhider/WordCount$IntSumReducer.class
Writing to replaceOutput/cfhider/WordCount.class
Writing to replaceOutput/cfhider/WordCount$TokenizerMapper.class
Writing to replaceOutput/invoker/sgx_invoker.class
Soot finished on Wed Apr 21 17:18:18 CST 2021
Soot has run for 0 min. 36 sec.
ok
