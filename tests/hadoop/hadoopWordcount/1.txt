replaceOutput/cfhider/WordCount$IntSumReducer.class
replaceOutput/cfhider/WordCount.class
replaceOutput/cfhider/WordCount$TokenizerMapper.class
replaceOutput/invoker/sgx_invoker.class
replaceOutput/ReplaceTestforHadoopWordCount.jar
Soot started on Fri May 14 14:14:58 CST 2021
Warning: org.codehaus.jackson.JsonGenerator is a phantom class!
Warning: org.codehaus.jackson.JsonFactory is a phantom class!
Warning: org.codehaus.jackson.map.ObjectMapper is a phantom class!
Warning: org.codehaus.jackson.map.JsonMappingException is a phantom class!
Warning: org.codehaus.jackson.JsonParseException is a phantom class!
Warning: org.apache.commons.io.FileUtils is a phantom class!
Warning: org.apache.commons.codec.binary.Base64 is a phantom class!
Warning: org.mortbay.util.ajax.JSON is a phantom class!
Warning: org.apache.commons.lang.StringUtils is a phantom class!
Warning: org.mortbay.jetty.webapp.WebAppContext is a phantom class!
Warning: javax.servlet.http.HttpServlet is a phantom class!
Warning: javax.servlet.http.HttpServletRequest is a phantom class!
Warning: javax.servlet.http.HttpServletResponse is a phantom class!
Warning: javax.servlet.ServletContext is a phantom class!
Warning: javax.servlet.ServletException is a phantom class!
Warning: org.mortbay.jetty.Connector is a phantom class!
Warning: org.mortbay.jetty.Handler is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandlerCollection is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler$SContext is a phantom class!
Warning: com.sun.jersey.spi.container.servlet.ServletContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.DefaultServlet is a phantom class!
Warning: org.mortbay.jetty.nio.SelectChannelConnector is a phantom class!
Warning: org.mortbay.thread.ThreadPool is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterMapping is a phantom class!
Warning: org.mortbay.util.MultiException is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHandler is a phantom class!
Warning: org.mortbay.thread.QueuedThreadPool is a phantom class!
Warning: org.mortbay.jetty.security.SslSocketConnector is a phantom class!
Warning: org.mortbay.jetty.handler.ContextHandler is a phantom class!
Warning: org.mortbay.jetty.Server is a phantom class!
Warning: org.mortbay.jetty.HandlerContainer is a phantom class!
Warning: org.mortbay.jetty.servlet.FilterHolder is a phantom class!
Warning: org.mortbay.jetty.servlet.Context is a phantom class!
Warning: org.mortbay.jetty.servlet.ServletHolder is a phantom class!
Warning: org.apache.commons.httpclient.HttpMethod is a phantom class!
Warning: org.apache.commons.httpclient.HttpClient is a phantom class!
Warning: org.apache.commons.httpclient.methods.GetMethod is a phantom class!
Warning: org.apache.commons.httpclient.URI is a phantom class!
Warning: org.znerd.xmlenc.XMLOutputter is a phantom class!
Warning: org.apache.commons.configuration.PropertiesConfiguration is a phantom class!
Warning: org.apache.commons.math.util.MathUtils is a phantom class!
Warning: org.apache.commons.configuration.Configuration is a phantom class!
Warning: javax.servlet.ServletOutputStream is a phantom class!
Warning: javax.servlet.ServletConfig is a phantom class!
Warning: javax.servlet.ServletResponse is a phantom class!
Warning: javax.servlet.jsp.JspWriter is a phantom class!
Warning: javax.servlet.RequestDispatcher is a phantom class!
Warning: javax.servlet.ServletRequest is a phantom class!
Warning: javax.servlet.Filter is a phantom class!
Warning: javax.servlet.FilterChain is a phantom class!
Warning: javax.servlet.FilterConfig is a phantom class!
Warning: org.mortbay.jetty.security.ServletSSL is a phantom class!
Warning: org.mortbay.io.EndPoint is a phantom class!
Warning: org.mortbay.jetty.Request is a phantom class!
Warning: org.apache.log4j.Level is a phantom class!
Warning: org.apache.log4j.Logger is a phantom class!
Warning: org.apache.commons.lang.ArrayUtils is a phantom class!
Warning: org.apache.log4j.LogManager is a phantom class!
Warning: org.apache.log4j.Appender is a phantom class!
Warning: javax.ws.rs.GET is a phantom class!
Warning: javax.ws.rs.POST is a phantom class!
Warning: javax.ws.rs.core.Context is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilters is a phantom class!
Warning: javax.ws.rs.Produces is a phantom class!
Warning: javax.ws.rs.core.Response is a phantom class!
Warning: javax.ws.rs.Path is a phantom class!
Warning: javax.ws.rs.PUT is a phantom class!
Warning: javax.ws.rs.DefaultValue is a phantom class!
Warning: javax.ws.rs.PathParam is a phantom class!
Warning: javax.ws.rs.QueryParam is a phantom class!
Warning: javax.ws.rs.Consumes is a phantom class!
Warning: org.mortbay.log.Log is a phantom class!
Warning: org.apache.commons.daemon.Daemon is a phantom class!
Warning: org.apache.commons.daemon.DaemonContext is a phantom class!
Warning: javax.ws.rs.DELETE is a phantom class!
Warning: javax.ws.rs.core.StreamingOutput is a phantom class!
Warning: org.apache.commons.configuration.SubsetConfiguration is a phantom class!
Warning: org.apache.commons.configuration.ConfigurationException is a phantom class!
Warning: javax.servlet.http.HttpServletRequestWrapper is a phantom class!
Warning: org.apache.log4j.Priority is a phantom class!
Warning: org.apache.log4j.Category is a phantom class!
Warning: org.apache.log4j.FileAppender is a phantom class!
Warning: org.apache.log4j.helpers.QuietWriter is a phantom class!
Warning: org.apache.log4j.spi.LoggingEvent is a phantom class!
Warning: javax.ws.rs.core.Response$Status is a phantom class!
Warning: javax.ws.rs.core.Response$ResponseBuilder is a phantom class!
Warning: org.apache.log4j.AppenderSkeleton is a phantom class!
Warning: org.slf4j.Logger is a phantom class!
Warning: javax.servlet.http.Cookie is a phantom class!
Warning: org.slf4j.LoggerFactory is a phantom class!
Warning: com.sun.jersey.spi.container.ResourceFilter is a phantom class!
Warning: javax.ws.rs.core.MultivaluedMap is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequestFilter is a phantom class!
Warning: javax.ws.rs.core.UriBuilder is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerResponseFilter is a phantom class!
Warning: com.sun.jersey.spi.container.ContainerRequest is a phantom class!
No main class given. Inferred 'cfhider.WordCount' as main class.
[Call Graph] For information on where the call graph may be incomplete, use the verbose option to the cg phase.
[cf]SooClass:cfhider.WordCount$IntSumReducer
[cf] class: cfhider.WordCount$IntSumReducer
[cf]SooClass:cfhider.WordCount
[cf] class: cfhider.WordCount
[cf]SooClass:cfhider.WordCount$TokenizerMapper
[cf] class: cfhider.WordCount$TokenizerMapper
2021class name :<init>
2021class name :map
[cf] sootMethod a:map
[cf] sootMethod zystble
unit :r0 := @this: cfhider.WordCount$TokenizerMapper
Identity statment
the value=r0
the value=@this: cfhider.WordCount$TokenizerMapper
unit :r1 := @parameter0: java.lang.Object
Identity statment
the value=r1
the value=@parameter0: java.lang.Object
unit :r2 := @parameter1: org.apache.hadoop.io.Text
Identity statment
the value=r2
the value=@parameter1: org.apache.hadoop.io.Text
unit :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Identity statment
the value=r3
the value=@parameter2: org.apache.hadoop.mapreduce.Mapper$Context
unit :$r4 = new java.util.StringTokenizer
AssignStmt statment
the value=$r4
2021=false taintSourceName=$z0
the value=new java.util.StringTokenizer
2021=false taintSourceName=$z0
unit :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
AssignStmt statment
the value=$r6
2021=false taintSourceName=$z0
the value=r2
2021=false taintSourceName=$z0
the value=virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
2021=false taintSourceName=$z0
unit :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
unit :r5 = $r4
AssignStmt statment
the value=r5
2021=false taintSourceName=$z0
the value=$r4
2021=false taintSourceName=$z0
unit :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
AssignStmt statment
the value=$z0
2021=false taintSourceName=$z0
the value of newlist=[$z0]
unit :if $z0 == 0 goto return
If statment
the value=$z0
the value=0
unit :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
AssignStmt statment
the value=$r7
2021=false taintSourceName=$z0
the value=r0
2021=false taintSourceName=$z0
the value=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
2021=false taintSourceName=$z0
unit :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
AssignStmt statment
the value=$r8
2021=false taintSourceName=$z0
the value=r5
2021=false taintSourceName=$z0
the value=virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
2021=false taintSourceName=$z0
unit :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
unit :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
AssignStmt statment
the value=$r9
2021=false taintSourceName=$z0
the value=r0
2021=false taintSourceName=$z0
the value=r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
2021=false taintSourceName=$z0
unit :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
AssignStmt statment
the value=$r10
2021=false taintSourceName=$z0
the value=<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
2021=false taintSourceName=$z0
unit :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
unit :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
unit :return
2021class name :map
[cf] sootMethod a:map
[cf] sootMethod zystble
unit :r0 := @this: cfhider.WordCount$TokenizerMapper
Identity statment
the value=r0
the value=@this: cfhider.WordCount$TokenizerMapper
unit :r1 := @parameter0: java.lang.Object
Identity statment
the value=r1
the value=@parameter0: java.lang.Object
unit :r2 := @parameter1: java.lang.Object
Identity statment
the value=r2
the value=@parameter1: java.lang.Object
unit :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
Identity statment
the value=r3
the value=@parameter2: org.apache.hadoop.mapreduce.Mapper$Context
unit :$r4 = (org.apache.hadoop.io.Text) r2
AssignStmt statment
the value=$r4
2021=false taintSourceName=$z0
the value=r2
2021=false taintSourceName=$z0
the value=(org.apache.hadoop.io.Text) r2
2021=false taintSourceName=$z0
unit :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
unit :return
2021class name :<clinit>
[cf]SooClass:invoker.sgx_invoker
[CFMAP]2021:{cfhider.WordCount$IntSumReducer={}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}
[INVOKEMAP]2021size:3
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3f581365}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@2f616c60}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@25122aed
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@25122aed
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@25122aed
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@2f616c60}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@4bc0409e}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3ad26bec}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@4cab711f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@4cab711f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@4cab711f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3ad26bec}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@b8fd18c}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@646b50c2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@646b50c2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@646b50c2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={main=[I@4597c299}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={main=[I@4597c299}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{map=[$z0]}
[taint not hasActiveBody] sootMethod: <init>
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@31aed88a}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4e0a6581}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@c8e202e
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@c8e202e
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@c8e202e
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4e0a6581}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4e0a6581}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@46e2b272}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4d317eb9}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6c76cb46
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6c76cb46
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6c76cb46
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4d317eb9}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@4d317eb9}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@6b1b984b}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@60ab9adc}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@22441319
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@22441319
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@22441319
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@60ab9adc}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@60ab9adc}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@2341dfe2}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@694c361c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@694c361c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@694c361c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@f064442}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@a749e46}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6e430b06}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@7388ef77
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@7388ef77
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@7388ef77
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6e430b06}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@2321a8e3}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@76d6e119}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@15546d43
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@15546d43
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@15546d43
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@76d6e119}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@59d154a5}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@18fc8f3f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@18fc8f3f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@18fc8f3f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6e68ee80}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6d207de9}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@6d207de9}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@39d18083}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@773e06a8}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@9273cc1}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6f05a798
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@9273cc1}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@9273cc1}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@5c3e2519}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@73f5bb9e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@9f0bd8c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@9f0bd8c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@9f0bd8c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@73f5bb9e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@73f5bb9e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@1c2c376d}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@1aeae38e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@33018d70
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@33018d70
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@33018d70
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@1aeae38e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@1aeae38e}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@2aecce39}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@8f27f1d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@8f27f1d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@8f27f1d
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@3e0c4ab4}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@68774d81}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@708185bb}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@4772f1b1
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@708185bb}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@4b59c01c}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@715394e9}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@2655871f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@2655871f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@2655871f
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@715394e9}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@391a17e2}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@496884a9
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@496884a9
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@496884a9
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@702a83f7}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@6cdd98e5}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@6cdd98e5}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@20d71633}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@5f00b94e}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@2885e09c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@6d5d368c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@6d5d368c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@6d5d368c
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@2885e09c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@2885e09c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@2a8596c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@7a86c2d0}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@25602488
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@25602488
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@25602488
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@7a86c2d0}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@7a86c2d0}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@4afe6fe3}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@663c68c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@80149b
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@80149b
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@80149b
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@663c68c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@663c68c}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@58c8cc5e}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@559762a1
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[taint]SooClass:cfhider.WordCount$IntSumReducer
[taint] class: cfhider.WordCount$IntSumReducer
methList :{<init>=[], reduce=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@601613b7}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@45cc63ed}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6db48067}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@655a2275
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@655a2275
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@655a2275
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@6db48067}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@8c634f}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@cbd7d1}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@46c5dabf
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@46c5dabf
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@46c5dabf
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$IntSumReducer
method name :<init>
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void <init>()>
The data isgggg cfhider.WordCount$IntSumReducer <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@cbd7d1}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.IntWritable: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Reducer: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Reducer: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: org.apache.hadoop.io.Text  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: org.apache.hadoop.io.Text
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :i0 = 0
20210427node in :[]
普通复制语句1112:i0 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node in :[]
调用语句赋值给变量:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
20210427node out :[]
[taint328]a invoke <java.lang.Iterable: java.util.Iterator iterator()>
[taint328]a invoke 0
20210427node :$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node in :[]
调用语句赋值给变量:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: boolean hasNext()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
isoutSetContains  false value:i0 index:0
20210427node :$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
20210427node in :[]
普通复制语句1112:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
[taint source] u:r0
SourceList:[]
[taint source] u:r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
isoutSetContains  false value:r1 index:0
value:$r8
isoutSetContains  false value:$r8 index:1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node in :[]
调用语句赋值给变量:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
20210427node out :[]
[taint328]a invoke <java.util.Iterator: java.lang.Object next()>
[taint328]a invoke 0
20210427node :r5 = (org.apache.hadoop.io.IntWritable) $r6
20210427node in :[]
普通复制语句1112:r5 = (org.apache.hadoop.io.IntWritable) $r6
[taint source] u:$r6
SourceList:[]
[taint source] u:(org.apache.hadoop.io.IntWritable) $r6
SourceList:[]
20210427node out :[]
20210427node :$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node in :[]
调用语句赋值给变量:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.IntWritable: int get()>
[taint328]a invoke 0
20210427node :i0 = i0 + $i1
20210427node in :[]
普通复制语句1112:i0 = i0 + $i1
[taint source] u:i0
SourceList:[]
[taint source] u:$i1
SourceList:[]
[taint source] u:i0 + $i1
SourceList:[]
20210427node out :[]
20210427node :goto [?= $z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@679c55e5}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = i0 + $i1
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$i1 = virtualinvoke r5.<org.apache.hadoop.io.IntWritable: int get()>()
currStmt left value20210420:$i1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = (org.apache.hadoop.io.IntWritable) $r6
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = interfaceinvoke r4.<java.util.Iterator: java.lang.Object next()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Reducer$Context: void write(java.lang.Object,java.lang.Object)>(r1, $r8)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:r1
value:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.IntWritable: void set(int)>(i0)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void set(int)>
[taint328]i invoke 1
value:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$IntSumReducer: org.apache.hadoop.io.IntWritable result>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = interfaceinvoke r4.<java.util.Iterator: boolean hasNext()>()
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = interfaceinvoke r2.<java.lang.Iterable: java.util.Iterator iterator()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:i0 = 0
currStmt left value20210420:i0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: reduce
[]
class name :cfhider.WordCount$IntSumReducer
method name :reduce
method list :[]
clasname=cfhider.WordCount$IntSumReducer
methodname=reduce
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$IntSumReducer
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$IntSumReducer
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Iterable
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Iterable  index:1
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Iterable
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context  index:2
ClassName:cfhider.WordCount$IntSumReducer
MethodName:reduce
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Reducer$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r1
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r1
[taint source] u:r1
SourceList:[]
[taint source] u:(org.apache.hadoop.io.Text) r1
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
isoutSetContains  false value:$r4 index:0
value:r2
isoutSetContains  false value:r2 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$IntSumReducer: void reduce(java.lang.Object,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
The data isgggg cfhider.WordCount$IntSumReducer reduce [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>($r4, r2, r3)
[taint328]i invoke <cfhider.WordCount$IntSumReducer: void reduce(org.apache.hadoop.io.Text,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>
[taint328]i invoke 3
value:$r4
in here:[I@20b1b267
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r2
in here:[I@20b1b267
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@20b1b267
[invokemap]invoke:reduce  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r1
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount
[taint] class: cfhider.WordCount
methList :{<init>=[], main=[]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@48611a39}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@723798f5}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount
method name :<init>
method list :[]
clasname=cfhider.WordCount
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount
20210427node :specialinvoke r0.<java.lang.Object: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void <init>()>
The data isgggg cfhider.WordCount <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@723798f5}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<java.lang.Object: void <init>()>()
[taint328]i invoke <java.lang.Object: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: main
[]
class name :cfhider.WordCount
method name :main
method list :[]
clasname=cfhider.WordCount
methodname=main
sourcelist2021=[]
20210427node :r0 := @parameter0: java.lang.String[]
20210427node in :[]
[idStmt]iiiiiii r0 := @parameter0: java.lang.String[]  index:0
ClassName:cfhider.WordCount
MethodName:main
aaaa:0
20210427node out :[]
currStmt20210423:r0 := @parameter0: java.lang.String[]
20210427node :$r1 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r1 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
isoutSetContains  false value:"In this project, we test wordcount with SGX!\n" index:0
20210427node :$r6 = new org.apache.hadoop.conf.Configuration
20210427node in :[]
普通复制语句1112:$r6 = new org.apache.hadoop.conf.Configuration
[taint source] u:new org.apache.hadoop.conf.Configuration
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
20210427node :r2 = $r6
20210427node in :[]
普通复制语句1112:r2 = $r6
[taint source] u:$r6
SourceList:[]
20210427node out :[]
20210427node :$r7 = new org.apache.hadoop.util.GenericOptionsParser
20210427node in :[]
普通复制语句1112:$r7 = new org.apache.hadoop.util.GenericOptionsParser
[taint source] u:new org.apache.hadoop.util.GenericOptionsParser
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:r0
isoutSetContains  false value:r0 index:1
20210427node :r3 = $r7
20210427node in :[]
普通复制语句1112:r3 = $r7
[taint source] u:$r7
SourceList:[]
20210427node out :[]
20210427node :r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node in :[]
调用语句赋值给变量:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>
[taint328]a invoke 0
20210427node :l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$r8 = new org.apache.hadoop.mapreduce.Job
20210427node in :[]
普通复制语句1112:$r8 = new org.apache.hadoop.mapreduce.Job
[taint source] u:new org.apache.hadoop.mapreduce.Job
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
isoutSetContains  false value:r2 index:0
value:"word count"
isoutSetContains  false value:"word count" index:1
20210427node :r5 = $r8
20210427node in :[]
普通复制语句1112:r5 = $r8
[taint source] u:$r8
SourceList:[]
20210427node out :[]
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
isoutSetContains  false value:class "cfhider/WordCount" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
isoutSetContains  false value:class "cfhider/WordCount$TokenizerMapper" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
isoutSetContains  false value:class "cfhider/WordCount$IntSumReducer" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
isoutSetContains  false value:class "org/apache/hadoop/io/Text" index:0
20210427node :virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
isoutSetContains  false value:class "org/apache/hadoop/io/IntWritable" index:0
20210427node :$r9 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r9 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r10 = r4[0]
20210427node in :[]
普通复制语句1112:$r10 = r4[0]
[taint source] u:r4
SourceList:[]
[taint source] u:0
SourceList:[]
[taint source] u:r4[0]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
isoutSetContains  false value:$r10 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r9
isoutSetContains  false value:$r9 index:1
20210427node :$r11 = new org.apache.hadoop.fs.Path
20210427node in :[]
普通复制语句1112:$r11 = new org.apache.hadoop.fs.Path
[taint source] u:new org.apache.hadoop.fs.Path
SourceList:[]
20210427node out :[]
20210427node :$r12 = r4[1]
20210427node in :[]
普通复制语句1112:$r12 = r4[1]
[taint source] u:r4
SourceList:[]
[taint source] u:1
SourceList:[]
[taint source] u:r4[1]
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
isoutSetContains  false value:$r12 index:0
20210427node :staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
isoutSetContains  false value:r5 index:0
value:$r11
isoutSetContains  false value:$r11 index:1
20210427node :$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>
[taint328]a invoke 1
assi isoutSet  false value:1 index:0
20210427node :if $z0 == 0 goto $b2 = 1
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto $b2 = 1Stmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size0
ifValues1
20210427node :$b2 = 1
20210427node in :[]
普通复制语句1112:$b2 = 1
[taint source] u:1
SourceList:[]
20210427node out :[]
20210427node :$b2 = 0
20210427node in :[]
普通复制语句1112:$b2 = 0
[taint source] u:0
SourceList:[]
20210427node out :[]
20210427node :goto [?= b1 = $b2]
20210427node in :[]
20210427node out :[]
20210427node :b1 = $b2
20210427node in :[]
普通复制语句1112:b1 = $b2
[taint source] u:$b2
SourceList:[]
20210427node out :[]
20210427node :$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node in :[]
调用语句赋值给变量:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
20210427node out :[]
[taint328]a invoke <java.lang.System: long currentTimeMillis()>
[taint328]a invoke 0
20210427node :$l4 = $l3 - l0
20210427node in :[]
普通复制语句1112:$l4 = $l3 - l0
[taint source] u:$l3
SourceList:[]
[taint source] u:l0
SourceList:[]
[taint source] u:$l3 - l0
SourceList:[]
20210427node out :[]
20210427node :$d1 = (double) $l4
20210427node in :[]
普通复制语句1112:$d1 = (double) $l4
[taint source] u:$l4
SourceList:[]
[taint source] u:(double) $l4
SourceList:[]
20210427node out :[]
20210427node :d0 = $d1 / 1000.0
20210427node in :[]
普通复制语句1112:d0 = $d1 / 1000.0
[taint source] u:$d1
SourceList:[]
[taint source] u:1000.0
SourceList:[]
[taint source] u:$d1 / 1000.0
SourceList:[]
20210427node out :[]
20210427node :$r13 = <java.lang.System: java.io.PrintStream out>
20210427node in :[]
普通复制语句1112:$r13 = <java.lang.System: java.io.PrintStream out>
[taint source] u:<java.lang.System: java.io.PrintStream out>
SourceList:[]
20210427node out :[]
20210427node :$r14 = new java.lang.StringBuilder
20210427node in :[]
普通复制语句1112:$r14 = new java.lang.StringBuilder
[taint source] u:new java.lang.StringBuilder
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
20210427node :$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node in :[]
调用语句赋值给变量:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:"Job Finished in " index:0
20210427node :$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node in :[]
调用语句赋值给变量:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(double)>
[taint328]a invoke 1
assi isoutSet  false value:d0 index:0
20210427node :$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node in :[]
调用语句赋值给变量:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>
[taint328]a invoke 1
assi isoutSet  false value:" seconds" index:0
20210427node :$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <java.lang.StringBuilder: java.lang.String toString()>
[taint328]a invoke 0
20210427node :virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
isoutSetContains  false value:$r18 index:0
20210427node :staticinvoke <java.lang.System: void exit(int)>(b1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
isoutSetContains  false value:b1 index:0
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount: void main(java.lang.String[])>
The data isgggg cfhider.WordCount main [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <java.lang.System: void exit(int)>(b1)
[taint328]i invoke <java.lang.System: void exit(int)>
[taint328]i invoke 1
value:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r13.<java.io.PrintStream: void println(java.lang.String)>($r18)
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r18 = virtualinvoke $r17.<java.lang.StringBuilder: java.lang.String toString()>()
currStmt left value20210420:$r18
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r17 = virtualinvoke $r16.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds")
currStmt left value20210420:$r17
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r16 = virtualinvoke $r15.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d0)
currStmt left value20210420:$r16
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r15 = virtualinvoke $r14.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ")
currStmt left value20210420:$r15
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r14.<java.lang.StringBuilder: void <init>()>()
[taint328]i invoke <java.lang.StringBuilder: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r14 = new java.lang.StringBuilder
currStmt left value20210420:$r14
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r13 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r13
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:d0 = $d1 / 1000.0
currStmt left value20210420:d0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$d1 = (double) $l4
currStmt left value20210420:$d1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l4 = $l3 - l0
currStmt left value20210420:$l4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$l3 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:$l3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:b1 = $b2
currStmt left value20210420:b1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 0
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$b2 = 1
currStmt left value20210420:$b2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: boolean waitForCompletion(boolean)>(1)
currStmt left value20210420:$z0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r11)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.output.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r11.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r12)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r12 = r4[1]
currStmt left value20210420:$r12
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r11 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r11
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke staticinvoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>(r5, $r9)
[taint328]i invoke <org.apache.hadoop.mapreduce.lib.input.FileInputFormat: void addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)>
[taint328]i invoke 2
value:r5
value:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r9.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r10)
[taint328]i invoke <org.apache.hadoop.fs.Path: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r10 = r4[0]
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r9 = new org.apache.hadoop.fs.Path
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/IntWritable")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputValueClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/IntWritable"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/Text")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setOutputKeyClass(java.lang.Class)>
[taint328]i invoke 1
value:class "org/apache/hadoop/io/Text"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setReducerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>(class "cfhider/WordCount$IntSumReducer")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setCombinerClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$IntSumReducer"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>(class "cfhider/WordCount$TokenizerMapper")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setMapperClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount$TokenizerMapper"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r5.<org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>(class "cfhider/WordCount")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void setJarByClass(java.lang.Class)>
[taint328]i invoke 1
value:class "cfhider/WordCount"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r5 = $r8
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r8.<org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>(r2, "word count")
[taint328]i invoke <org.apache.hadoop.mapreduce.Job: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>
[taint328]i invoke 2
value:r2
value:"word count"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r8 = new org.apache.hadoop.mapreduce.Job
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:l0 = staticinvoke <java.lang.System: long currentTimeMillis()>()
currStmt left value20210420:l0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r4 = virtualinvoke r3.<org.apache.hadoop.util.GenericOptionsParser: java.lang.String[] getRemainingArgs()>()
currStmt left value20210420:r4
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r3 = $r7
currStmt left value20210420:r3
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r7.<org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>(r2, r0)
[taint328]i invoke <org.apache.hadoop.util.GenericOptionsParser: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>
[taint328]i invoke 2
value:r2
value:r0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r7 = new org.apache.hadoop.util.GenericOptionsParser
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r2 = $r6
currStmt left value20210420:r2
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r6.<org.apache.hadoop.conf.Configuration: void <init>()>()
[taint328]i invoke <org.apache.hadoop.conf.Configuration: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r6 = new org.apache.hadoop.conf.Configuration
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r1.<java.io.PrintStream: void println(java.lang.String)>("In this project, we test wordcount with SGX!\n")
[taint328]i invoke <java.io.PrintStream: void println(java.lang.String)>
[taint328]i invoke 1
value:"In this project, we test wordcount with SGX!\n"
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = <java.lang.System: java.io.PrintStream out>
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:cfhider.WordCount$TokenizerMapper
[taint] class: cfhider.WordCount$TokenizerMapper
methList :{<init>=[], <clinit>=[], map=[$z0]}
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@66e15cdb}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@5ad29d4f}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@3955dc1e}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@33e652fa
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@33e652fa
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@33e652fa
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@3955dc1e}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@3955dc1e}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@5651b5b4}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@e7068b2}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@75e98585
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@75e98585
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@75e98585
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@e7068b2}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@e7068b2}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@363d1b3d}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@65c75d9c}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@3d2e0f8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@3d2e0f8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@3d2e0f8
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@65c75d9c}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <init>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<init>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<init>
sourcelist2021=[]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
20210427node :$r1 = new org.apache.hadoop.io.Text
20210427node in :[]
普通复制语句1112:$r1 = new org.apache.hadoop.io.Text
[taint source] u:new org.apache.hadoop.io.Text
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
20210427node :r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
20210427node in :[]
普通复制语句1112:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
[taint source] u:r0
SourceList:[]
[taint source] u:$r1
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <init>()>
The data isgggg cfhider.WordCount$TokenizerMapper <init> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@65c75d9c}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word> = $r1
currStmt left value20210420:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r1.<org.apache.hadoop.io.Text: void <init>()>()
[taint328]i invoke <org.apache.hadoop.io.Text: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r1 = new org.apache.hadoop.io.Text
currStmt left value20210420:$r1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke r0.<org.apache.hadoop.mapreduce.Mapper: void <init>()>()
[taint328]i invoke <org.apache.hadoop.mapreduce.Mapper: void <init>()>
[taint328]i invoke 0
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: org.apache.hadoop.io.Text
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: org.apache.hadoop.io.Text  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: org.apache.hadoop.io.Text
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = new java.util.StringTokenizer
20210427node in :[]
普通复制语句1112:$r4 = new java.util.StringTokenizer
[taint source] u:new java.util.StringTokenizer
SourceList:[$z0]
20210427node out :[]
20210427node :$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node in :[]
调用语句赋值给变量:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
20210427node out :[]
[taint328]a invoke <org.apache.hadoop.io.Text: java.lang.String toString()>
[taint328]a invoke 0
20210427node :specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
isoutSetContains  false value:$r6 index:0
20210427node :r5 = $r4
20210427node in :[]
普通复制语句1112:r5 = $r4
[taint source] u:$r4
SourceList:[$z0]
20210427node out :[]
20210427node :$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node in :[]
调用语句赋值给变量:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
[taint328]a invoke 0
20210427node :if $z0 == 0 goto return
20210427node in :[]
20210427node out :[]
Have
Stmt if :if $z0 == 0 goto returnStmt if value:$z0 == 0the value=$z0
the value=0
maintainValues.size1
ifValues1
20210427node :return
20210427node in :[]
20210427node out :[]
20210427node :$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node in :[]
调用语句赋值给变量:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
20210427node out :[]
[taint328]a invoke <java.util.StringTokenizer: java.lang.String nextToken()>
[taint328]a invoke 0
20210427node :virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
isoutSetContains  false value:$r8 index:0
20210427node :$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
20210427node in :[]
普通复制语句1112:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
[taint source] u:r0
SourceList:[$z0]
[taint source] u:r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
SourceList:[$z0]
20210427node out :[]
20210427node :$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
20210427node in :[]
普通复制语句1112:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
[taint source] u:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
isoutSetContains  false value:$r9 index:0
value:$r10
isoutSetContains  false value:$r10 index:1
20210427node :goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@9afbbbe}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
[taint328]i invoke <org.apache.hadoop.mapreduce.TaskInputOutputContext: void write(java.lang.Object,java.lang.Object)>
[taint328]i invoke 2
value:$r9
value:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
currStmt left value20210420:$r10
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r9
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
[taint328]i invoke <org.apache.hadoop.io.Text: void set(java.lang.String)>
[taint328]i invoke 1
value:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
currStmt left value20210420:$r8
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
currStmt left value20210420:$r7
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
Have
the value=$z0
the value=0
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currStmt left value20210420:$z0
20210419===virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint329]i invoke $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
[taint328]i invoke <java.util.StringTokenizer: boolean hasMoreTokens()>
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:r5 = $r4
currStmt left value20210420:r5
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
[taint328]i invoke <java.util.StringTokenizer: void <init>(java.lang.String)>
[taint328]i invoke 1
value:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
currStmt left value20210420:$r6
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = new java.util.StringTokenizer
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: map
[$z0]
class name :cfhider.WordCount$TokenizerMapper
method name :map
method list :[$z0]
clasname=cfhider.WordCount$TokenizerMapper
methodname=map
sourcelist2021=[$z0]
20210427node :r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node in :[]
20210427node out :[]
currStmt20210423:r0 := @this: cfhider.WordCount$TokenizerMapper
20210427node :r1 := @parameter0: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r1 := @parameter0: java.lang.Object  index:0
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r1 := @parameter0: java.lang.Object
20210427node :r2 := @parameter1: java.lang.Object
20210427node in :[]
[idStmt]iiiiiii r2 := @parameter1: java.lang.Object  index:1
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r2 := @parameter1: java.lang.Object
20210427node :r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node in :[]
[idStmt]iiiiiii r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context  index:2
ClassName:cfhider.WordCount$TokenizerMapper
MethodName:map
aaaa:0
20210427node out :[]
currStmt20210423:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
20210427node :$r4 = (org.apache.hadoop.io.Text) r2
20210427node in :[]
普通复制语句1112:$r4 = (org.apache.hadoop.io.Text) r2
[taint source] u:r2
SourceList:[$z0]
[taint source] u:(org.apache.hadoop.io.Text) r2
SourceList:[$z0]
20210427node out :[]
20210427node :virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
20210427node in :[]
20210427node out :[]
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
isoutSetContains  false value:r1 index:0
value:$r4
isoutSetContains  false value:$r4 index:1
value:r3
isoutSetContains  false value:r3 index:2
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>
The data isgggg cfhider.WordCount$TokenizerMapper map [$z0] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@704ebbe9}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
[taint329]i invoke virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
[taint328]i invoke <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>
[taint328]i invoke 3
value:r1
in here:[I@4112f799
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:$r4
in here:[I@4112f799
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
value:r3
in here:[I@4112f799
[invokemap]invoke:map  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
currStmt20210420:$r4 = (org.apache.hadoop.io.Text) r2
currStmt left value20210420:$r4
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[$z0]
Coming in Backward Analysis
doAnalysis endqqqqqqq.....
come here
[taint into] sootMethod: <clinit>
[]
class name :cfhider.WordCount$TokenizerMapper
method name :<clinit>
method list :[]
clasname=cfhider.WordCount$TokenizerMapper
methodname=<clinit>
sourcelist2021=[]
20210427node :$r0 = new org.apache.hadoop.io.IntWritable
20210427node in :[]
普通复制语句1112:$r0 = new org.apache.hadoop.io.IntWritable
[taint source] u:new org.apache.hadoop.io.IntWritable
SourceList:[]
20210427node out :[]
20210427node :specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
20210427node in :[]
20210427node out :[]
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
isoutSetContains  false value:1 index:0
20210427node :<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
20210427node in :[]
普通复制语句1112:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
[taint source] u:$r0
SourceList:[]
20210427node out :[]
20210427node :return
20210427node in :[]
20210427node out :[]
analysis.outSet.size():0
The data isgggg 
<cfhider.WordCount$TokenizerMapper: void <clinit>()>
The data isgggg cfhider.WordCount$TokenizerMapper <clinit> [] {cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}  {cfhider.WordCount$IntSumReducer={reduce=[I@48cb6287}, cfhider.WordCount$TokenizerMapper={map=[I@704ebbe9}, cfhider.WordCount={main=[I@201b3768}}
Coming...
doAnalysis Startingqqqqqqqq.....
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one> = $r0
currStmt left value20210420:<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
[taint329]i invoke specialinvoke $r0.<org.apache.hadoop.io.IntWritable: void <init>(int)>(1)
[taint328]i invoke <org.apache.hadoop.io.IntWritable: void <init>(int)>
[taint328]i invoke 1
value:1
srcValue=[]
destValue:[]
taint data:[]
Coming in Backward Analysis
currStmt20210420:$r0 = new org.apache.hadoop.io.IntWritable
currStmt left value20210420:$r0
doAnalysis endqqqqqqq.....
come here
[taint]SooClass:invoker.sgx_invoker
[========CFMAP=======after taint===]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}
[==========memberVariables==after taint=========]:{}
[============staticmemberVariables=====after taint=======]:{}
[========INVOKE==========] class = cfhider.WordCount$IntSumReducer method = reduce, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount$TokenizerMapper method = map, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[========INVOKE==========] class = cfhider.WordCount method = main, Value1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Key class = cfhider.WordCount$IntSumReducer, Value = {<init>=[], reduce=[]}
Key1 method = <init>, Value1 = []
Key1 method = reduce, Value1 = []
Key class = cfhider.WordCount$TokenizerMapper, Value = {<init>=[], <clinit>=[], map=[$z0]}
Key1 method = <init>, Value1 = []
Key1 method = <clinit>, Value1 = []
Key1 method = map, Value1 = [$z0]
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
tvalue:$z0   type:boolean
Key class = cfhider.WordCount, Value = {<init>=[], main=[]}
Key1 method = <init>, Value1 = []
Key1 method = main, Value1 = []
[add member]SooClass:cfhider.WordCount$IntSumReducer
[add member] class: cfhider.WordCount$IntSumReducer
[add member]SooClass:cfhider.WordCount
[add member] class: cfhider.WordCount
[add member]SooClass:cfhider.WordCount$TokenizerMapper
[add member] class: cfhider.WordCount$TokenizerMapper
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
[add member]SooClass:invoker.sgx_invoker
[========CFMAP==========]:{cfhider.WordCount$IntSumReducer={<init>=[], reduce=[]}, cfhider.WordCount$TokenizerMapper={<init>=[], <clinit>=[], map=[$z0]}, cfhider.WordCount={<init>=[], main=[]}}
[==========memberVariables===========]:{}
[============staticmemberVariables============]:{}
Transforming cfhider.WordCount$IntSumReducer... 
classname20210512: 1
classname20210512:cfhider.WordCount$IntSumReducer
MethodName20210512:<init>
classname20210512: 1
classname20210512:cfhider.WordCount$IntSumReducer
MethodName20210512:reduce
classname20210512: 1
classname20210512:cfhider.WordCount$IntSumReducer
MethodName20210512:reduce
Transforming cfhider.WordCount... 
classname20210512: 1
classname20210512:cfhider.WordCount
MethodName20210512:<init>
classname20210512: 1
classname20210512:cfhider.WordCount
MethodName20210512:main
Transforming cfhider.WordCount$TokenizerMapper... 
classname20210512: 1
classname20210512:cfhider.WordCount$TokenizerMapper
MethodName20210512:<init>
classname20210512: 1
classname20210512:cfhider.WordCount$TokenizerMapper
MethodName20210512:map
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=r5
tLocal=$r6
tLocal=$z0
tLocal=$r7
tLocal=$r8
tLocal=$r9
tLocal=$r10
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: org.apache.hadoop.io.Text
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = new java.util.StringTokenizer
====currScanPre==0404=====$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
====currScanPre==0404=====specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
====currScanPre==0404=====r5 = $r4
====currScanPre==0404=====$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
====currScanPre==0404=====if $z0 == 0 goto return
====currScanPre==0404=====$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
====currScanPre==0404=====virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
====currScanPre==0404=====$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>
====currScanPre==0404=====$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>
====currScanPre==0404=====virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
====currScanPre==0404=====goto [?= $z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, r5, $r6, $z0, $r7, $r8, $r9, $r10, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals1
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: org.apache.hadoop.io.Text
0424 identity Vals r2 := @parameter1: org.apache.hadoop.io.Text
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
 line632 current stmt is: ----------#$r4 = new java.util.StringTokenizer#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[new java.util.StringTokenizer]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
r5: init stmt will be inserted into jimplefile! :r5 = null
$r6: init stmt will be inserted into jimplefile! :$r6 = null
$z0: init stmt will be inserted into jimplefile! :$z0 = 0
$r7: init stmt will be inserted into jimplefile! :$r7 = null
$r8: init stmt will be inserted into jimplefile! :$r8 = null
$r9: init stmt will be inserted into jimplefile! :$r9 = null
$r10: init stmt will be inserted into jimplefile! :$r10 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = new java.util.StringTokenizer
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = new java.util.StringTokenizer
ZYSTBLE condValsTypeArray:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
ZYSTBLE 8.31:
ValueInitStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean initValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, invokeUUID, invokeLineNo)#--
currProStmt is NewExpr: $r4 = new java.util.StringTokenizer;
currProStmt is NewExpr TypeString: java.util.StringTokenizer;
line 701 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
 line632 current stmt is: ----------#$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()#----------------
currDefVals:[$r6]
currDefVals after retainAll:[]
currUseVals:[r2, virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()]
currUseVals after retainAll:[]
assi methodname :toString
assi classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive:$r6 = virtualinvoke r2.<org.apache.hadoop.io.Text: java.lang.String toString()>()
line 701 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
 line632 current stmt is: ----------#specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r4, $r6, specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)]
currUseVals after retainAll:[]
methodname :<init>
classname :java.util.StringTokenizer
currProStmt isn't sensitive invokestmt:specialinvoke $r4.<java.util.StringTokenizer: void <init>(java.lang.String)>($r6)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#r5 = $r4#----------------
 line632 current stmt is: ----------#r5 = $r4#----------------
currDefVals:[r5]
currDefVals after retainAll:[]
currUseVals:[$r4]
currUseVals after retainAll:[]
currProStmt is AssignStmt: r5 = $r4;
line 701 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
 line632 current stmt is: ----------#$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()#----------------
currDefVals:[$z0]
currDefVals after retainAll:[$z0]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]
currUseVals after retainAll:[]
assi methodname :hasMoreTokens
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
currProStmt will change to GET:$z0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()
new assi:$z0 = tmpResult0
ass r curr pro Unit: tmpResult0;
ass r curr pro Unit type: boolean;
ass l curr pro Unit: $z0;
ass l curr pro Unit type: boolean;
=curr pro Unit: tmpResult0;
Local exp********tmpResult0*************
values:********tmpResult0*************
values.type:********boolean*************
rightCondValue1: []
condVals: [$z0]
rightCondValue2: []
start insert before currStmt: ++++++++++++++++++++++++++ $z0 = tmpResult0++++++++++++++++++++++
=leftOpValue.type==boolean
=leftOpValue==$z0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
returnTypeIndex=1
pos_index=0
return_index=100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
values.get(0)=tmpResult0
pos_index=-1
<<<<<<ZYSTBLE>>>>>> tuple-0 update: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values.size=1
0515 :tmpResult0 boolean
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
add: else :tmpResult0
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
loc.equals: index:0
loggedValue type:boolean
ZY newInvokeStmt to insert is: ++++++++++++++++++++++++++ virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult0)++++++++++++++++++++++
add: loc :virtualinvoke sgxInvoker.<invoker.sgx_invoker: void add(int)>(tmpResult0)  index:0
left_index:0
right_index:-1
return_index:100
counter:0
stmt update has no second operand:********-1*************
1111222111
1111555111
line 701 current stmt is: ----------#if $z0 == 0 goto return#----------------
 line632 current stmt is: ----------#if $z0 == 0 goto return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$z0, 0, $z0 == 0]
currUseVals after retainAll:[$z0]
the value=$z0
the value=0
the value if stmt:[$z0]
the method SourceList:[$z0]
 curr pro Unit: $z0 == 0;
Local exp********$z0*************
Constant exp********0*************
operator:******** == *************
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
<<<<<<ZYSTBLE>>>>>> tuple-0 branch: ++++++++++++++++++++++++++ 1++++++++++++++++++++++
values0 is in condvals!
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********boolean*************
val_type is:====1
pos_index is:====0
left_index is:====100
<<<<<<ZYSTBLE>>>>>> in Function TypeIndex typeStr:********int*************
values1 is constant!
left_index：====b==:100
right_index：===b===:int_0
operator：===b===:[ == ]
re：===b===:-1
counter：===b===:1
assignStmt to insert is: ++++++++++++++++++++++++++ branchInvokeResult = virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean getBooleanValue(java.lang.String)>(getUUID)++++++++++++++++++++++
start insert before currStmt: ++++++++++++++++++++++++++ if branchInvokeResult == 1 goto return++++++++++++++++++++++
currProStmt is IfStmt: if branchInvokeResult == 1 goto return;
line 701 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r7]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r7 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
 line632 current stmt is: ----------#$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()#----------------
currDefVals:[$r8]
currDefVals after retainAll:[]
currUseVals:[r5, virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()]
currUseVals after retainAll:[]
assi methodname :nextToken
assi classname :java.util.StringTokenizer
currProStmt isn't sensitive:$r8 = virtualinvoke r5.<java.util.StringTokenizer: java.lang.String nextToken()>()
line 701 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
 line632 current stmt is: ----------#virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[$r7, $r8, virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)]
currUseVals after retainAll:[]
methodname :set
classname :org.apache.hadoop.io.Text
currProStmt isn't sensitive invokestmt:virtualinvoke $r7.<org.apache.hadoop.io.Text: void set(java.lang.String)>($r8)
currProStmt isn't sensitive argList:1
line 701 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
 line632 current stmt is: ----------#$r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>#----------------
currDefVals:[$r9]
currDefVals after retainAll:[]
currUseVals:[r0, r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r9 = r0.<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.Text word>;
line 701 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
 line632 current stmt is: ----------#$r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>#----------------
currDefVals:[$r10]
currDefVals after retainAll:[]
currUseVals:[<cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>]
currUseVals after retainAll:[]
currProStmt is AssignStmt: $r10 = <cfhider.WordCount$TokenizerMapper: org.apache.hadoop.io.IntWritable one>;
line 701 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
 line632 current stmt is: ----------#virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r3, $r9, $r10, virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)]
currUseVals after retainAll:[]
methodname :write
classname :org.apache.hadoop.mapreduce.Mapper$Context
currProStmt isn't sensitive invokestmt:virtualinvoke r3.<org.apache.hadoop.mapreduce.Mapper$Context: void write(java.lang.Object,java.lang.Object)>($r9, $r10)
currProStmt isn't sensitive argList:2
line 701 current stmt is: ----------#goto [?= tmpResult0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
 line632 current stmt is: ----------#goto [?= tmpResult0 = virtualinvoke r5.<java.util.StringTokenizer: boolean hasMoreTokens()>()]#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>;
A
C2
B
ValueDeleteStmt is:#virtualinvoke sgxInvoker.<invoker.sgx_invoker: boolean deleteValueInEnclave(java.lang.String,java.lang.String,long)>(getUUID, "", 0L)#--
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
classname20210512: 1
classname20210512:cfhider.WordCount$TokenizerMapper
MethodName20210512:map
<<!!!!!!START!!!!!!>>start insertting at class: cfhider.WordCount$TokenizerMapper
<<!!!!!!START!!!!!!>>start processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
tLocal=r0
tLocal=r1
tLocal=r2
tLocal=r3
tLocal=$r4
tLocal=invokeLineNo
tLocal=getUUID
tLocal=invokeUUID
tLocal=branchInvokeResult
tLocal=sgxInvoker
**********************Line376
====currScanPre==0404=====r0 := @this: cfhider.WordCount$TokenizerMapper
====currScanPre==0404=====r1 := @parameter0: java.lang.Object
====currScanPre==0404=====r2 := @parameter1: java.lang.Object
====currScanPre==0404=====r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
====currScanPre==0404=====$r4 = (org.apache.hadoop.io.Text) r2
====currScanPre==0404=====virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
====currScanPre==0404=====return
**********************Line456
***zy+++lastIdentityStmt is： r0 := @this: cfhider.WordCount$TokenizerMapper;
localArray:[r0, r1, r2, r3, $r4, invokeLineNo, getUUID, invokeUUID, branchInvokeResult, sgxInvoker]
ok condVals0
currProStmt is IdentityStmt:r0 := @this: cfhider.WordCount$TokenizerMapper
currProStmt is IdentityStmt:r1 := @parameter0: java.lang.Object
0424 identity Vals r1 := @parameter0: java.lang.Object
currProStmt is IdentityStmt:r2 := @parameter1: java.lang.Object
0424 identity Vals r2 := @parameter1: java.lang.Object
currProStmt is IdentityStmt:r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
0424 identity Vals r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
line 701 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
 line632 current stmt is: ----------#$r4 = (org.apache.hadoop.io.Text) r2#----------------
currDefVals:[$r4]
currDefVals after retainAll:[]
currUseVals:[r2, (org.apache.hadoop.io.Text) r2]
currUseVals after retainAll:[]
r0: has been inited in original javafile!
r1: has been inited in original javafile!
r2: has been inited in original javafile!
r3: has been inited in original javafile!
$r4: init stmt will be inserted into jimplefile! :$r4 = null
invokeLineNo: init stmt will be inserted into jimplefile! :invokeLineNo = 0L
getUUID: init stmt will be inserted into jimplefile! :getUUID = null
invokeUUID: init stmt will be inserted into jimplefile! :invokeUUID = null
branchInvokeResult: init stmt will be inserted into jimplefile! :branchInvokeResult = 0
sgxInvoker: init stmt will be inserted into jimplefile! :sgxInvoker = null
2199 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
2204 stmt: sgxInvoker = new invoker.sgx_invoker
2206 currStmt: $r4 = (org.apache.hadoop.io.Text) r2
currProStmt is AssignStmt: $r4 = (org.apache.hadoop.io.Text) r2;
line 701 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
 line632 current stmt is: ----------#virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[r0, r1, $r4, r3, virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)]
currUseVals after retainAll:[]
methodname :map
classname :cfhider.WordCount$TokenizerMapper
currProStmt isn't sensitive invokestmt:virtualinvoke r0.<cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.Mapper$Context)>(r1, $r4, r3)
currProStmt isn't sensitive argList:3
line 701 current stmt is: ----------#return#----------------
 line632 current stmt is: ----------#return#----------------
currDefVals:[]
currDefVals after retainAll:[]
currUseVals:[]
currUseVals after retainAll:[]
currProStmt return stmt before deleteValuestmt: return
<<!!!!!!ZYreturn!!!!!!>>this processing function: <cfhider.WordCount$TokenizerMapper: void map(java.lang.Object,java.lang.Object,org.apache.hadoop.mapreduce.Mapper$Context)>;
***++++++lastIdentityStmt is:++++++++++r3 := @parameter2: org.apache.hadoop.mapreduce.Mapper$Context
classname20210512: 1
classname20210512:cfhider.WordCount$TokenizerMapper
MethodName20210512:<clinit>
Transforming invoker.sgx_invoker... 
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:<init>
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:sgx_invoker
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:clear
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:add
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:setCounter
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:setCuuid
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:initenclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:closeenclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getUUID
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:initArrayInEnclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:initValueInEnclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:deleteValueInEnclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:updateValueInEnclave
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:updateMultArray
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getBooleanValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getIntValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getIntArray
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getDoubleArray
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getByteArray
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getFloatValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getDoubleValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getCharValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getLongValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:getByteValue
classname20210512: 1
classname20210512:invoker.sgx_invoker
MethodName20210512:<clinit>
Writing to replaceOutput/cfhider/WordCount$IntSumReducer.class
Writing to replaceOutput/cfhider/WordCount.class
Writing to replaceOutput/cfhider/WordCount$TokenizerMapper.class
Writing to replaceOutput/invoker/sgx_invoker.class
Soot finished on Fri May 14 14:15:36 CST 2021
Soot has run for 0 min. 37 sec.
ok
